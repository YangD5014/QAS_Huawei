{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from mindquantum.algorithm.nisq import HardwareEfficientAnsatz,RYFull\n",
    "from mindquantum.core.parameterresolver import  PRGenerator\n",
    "import numpy as np\n",
    "from mindquantum.core.gates import RX, RY, RZ, H, X, Y, Z, I,CNOT\n",
    "from mindquantum.core.circuit import Circuit,UN\n",
    "import mindspore as ms\n",
    "import pickle\n",
    "from mindquantum.core.parameterresolver import PRGenerator\n",
    "import random\n",
    "from mindspore import Tensor,ops\n",
    "import tensorcircuit as tc\n",
    "import tensorflow as tf\n",
    "import mindspore.numpy as mnp\n",
    "from DQAS_tool import wash_pr,Mindspore_ansatz_micro,best_from_structure\n",
    "from DQAS_tool import  sampling_from_structure,zeroslike_grad_nnp_micro,nmf_gradient,vag_nnp_micro,DQAS_accuracy\n",
    "import sys\n",
    "from typing import Union\n",
    "sys.path.append('..')\n",
    "from Test_tool import Test_ansatz\n",
    "from data_processing import X_train,X_test,y_train,y_test\n",
    "from mindquantum.core.circuit import change_param_name,apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_pool = PRGenerator('pool')\n",
    "parameterized_circuit= \\\n",
    "[UN(RX(pr_pool.new()),maps_obj=[0])+I.on(1),\n",
    " UN(RX(pr_pool.new()),maps_obj=[1])+I.on(0),\n",
    " UN(RX(pr_pool.new()),maps_obj=[0],maps_ctrl=[1]),\n",
    " UN(RX(pr_pool.new()),maps_obj=[1],maps_ctrl=[0]),\n",
    " UN(RY(pr_pool.new()),maps_obj=[0])+I.on(1),\n",
    " UN(RY(pr_pool.new()),maps_obj=[1])+I.on(0),\n",
    " UN(RY(pr_pool.new()),maps_obj=[0],maps_ctrl=[1]),\n",
    " UN(RY(pr_pool.new()),maps_obj=[1],maps_ctrl=[0]),\n",
    " UN(RZ(pr_pool.new()),maps_obj=[0])+I.on(1),\n",
    " UN(RZ(pr_pool.new()),maps_obj=[1])+I.on(0),\n",
    " UN(RZ(pr_pool.new()),maps_obj=[0],maps_ctrl=[1]),\n",
    " UN(RZ(pr_pool.new()),maps_obj=[1],maps_ctrl=[0]),]\n",
    "\n",
    "\n",
    "unparameterized_circuit = \\\n",
    "[UN(X,maps_obj=[0],maps_ctrl=[1]),\n",
    " UN(X,maps_obj=[1],maps_ctrl=[0]),\n",
    " UN(Z,maps_obj=[0],maps_ctrl=[1]),\n",
    " UN(Z,maps_obj=[1],maps_ctrl=[0]),\n",
    " UN(Y,maps_obj=[0],maps_ctrl=[1]),\n",
    " UN(Y,maps_obj=[1],maps_ctrl=[0]),\n",
    " ]\n",
    "ansatz_pr = PRGenerator('ansatz')\n",
    "shape_parametized = len(parameterized_circuit)\n",
    "shape_unparameterized = len(unparameterized_circuit)\n",
    "num_layer=7\n",
    "shape_nnp = (7,num_layer,shape_parametized)\n",
    "shape_stp = (num_layer,shape_unparameterized+shape_parametized)\n",
    "stddev = 0.03\n",
    "nnp = np.random.normal(loc=0.0, scale=stddev, size=shape_nnp)\n",
    "stp = np.random.normal(loc=0.0, scale=stddev, size=shape_stp)\n",
    "ops_onehot = ops.OneHot(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_unparameterized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m best_structure \u001b[38;5;241m=\u001b[39m best_from_structure(stp)\n\u001b[0;32m----> 5\u001b[0m ansatz \u001b[38;5;241m=\u001b[39m \u001b[43mMindspore_ansatz_micro\u001b[49m\u001b[43m(\u001b[49m\u001b[43mStructure_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_structure\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparameterized_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameterized_circuit\u001b[49m\u001b[43m,\u001b[49m\u001b[43munparameterized_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munparameterized_circuit\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn_qbits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mac_vscode/华为 QAS 实习/DQAS/DQAS_tool.py:541\u001b[0m, in \u001b[0;36mMindspore_ansatz_micro\u001b[0;34m(Structure_p, parameterized_pool, unparameterized_pool, num_layer, n_qbits)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Structure_p\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m num_layer:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStructure_p shape must be equal to num_layer\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mStructure_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(parameterized_pool)\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mlen\u001b[39m(unparameterized_pool):\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStructure_p shape must be equal to size of pool\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Structure_p, np\u001b[38;5;241m.\u001b[39mndarray):\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "best_structure = best_from_structure(stp)\n",
    "\n",
    "\n",
    "\n",
    "ansatz = Mindspore_ansatz_micro(Structure_p=best_structure,parameterized_pool=parameterized_circuit,unparameterized_pool=unparameterized_circuit,num_layer=num_layer,n_qbits=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#微调\n",
    "nnp = data['ansatz_params_history'][-1]\n",
    "stp = data['structure_distribution_history'][-1]\n",
    "candidate = data['best_candidates_history'][-1]\n",
    "K = tc.set_backend(\"tensorflow\")\n",
    "ops_onehot = ops.OneHot(axis=-1)\n",
    "best_structure = ops_onehot(ms.Tensor(candidate),shape_parametized+shape_unparameterized,ms.Tensor(1),ms.Tensor(0))\n",
    "network_opt = tc.backend.optimizer(tf.keras.optimizers.Adam(1e-3))\n",
    "epochs = 600\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    infd, gnnp = vag_nnp_micro(Structure_params=best_structure,Ansatz_params=nnp,paramerterized_pool=parameterized_circuit,unparamerterized_pool=unparameterized_circuit,num_layer=num_layer,n_qbits=8)(ms.Tensor(X_train),ms.Tensor(y_train))\n",
    "    grad_nnp_zeroslike = zeroslike_grad_nnp_micro(batch_sturcture=best_structure,grad_nnp=gnnp[0],shape_parametized=shape_parametized,ansatz_parameters=nnp)\n",
    "\n",
    "    print(infd,gnnp)\n",
    "    nnp_tf = network_opt.update(tf.convert_to_tensor(grad_nnp_zeroslike), tf.convert_to_tensor(nnp))\n",
    "    nnp = nnp_tf.numpy()\n",
    "    if epoch % 10 == 0 or epoch == epochs - 1:\n",
    "        print(epoch, \"loss: \", infd)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ansatz.ansatz_params_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_from_structure(structures: np.array)->Tensor:\n",
    "    prob = ops.Softmax()(ms.Tensor(structures))\n",
    "    return ops.Argmax(axis=-1)(prob)\n",
    "\n",
    "def best_from_structure(structures: np.array)->Tensor:\n",
    "    return ops.Argmax(axis=-1)(ms.Tensor(structures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DQAS_tool import zeroslike_grad_nnp_micro\n",
    "grad_nnp_zeroslike = zeroslike_grad_nnp_micro(batch_sturcture=stp_onehot,grad_nnp=grad_nnp[0],shape_parametized=shape_parametized,ansatz_parameters=nnp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DQAS_tool import  sampling_from_structure,zeroslike_grad_nnp_micro,nmf_gradient,vag_nnp_micro,DQAS_accuracy\n",
    "#from DQAS_tool import  DQASAnsatz_from_result,DQAS_accuracy\n",
    "K = tc.set_backend(\"tensorflow\")\n",
    "lr = tf.keras.optimizers.schedules.ExponentialDecay(0.06, 100, 0.5)\n",
    "structure_opt = tc.backend.optimizer(tf.keras.optimizers.Adam(0.1))\n",
    "network_opt = tc.backend.optimizer(tf.keras.optimizers.Adam(lr))\n",
    "verbose = False\n",
    "# 设置超参数\n",
    "epochs = 800\n",
    "batch_size=100\n",
    "avcost1 = 0\n",
    "ops_onehot = ops.OneHot(axis=-1)\n",
    "batch_loss_history=[] # 记录每个epoch的batch_size损失值\n",
    "structure_distribution_history=[] # 记录每个epoch的结构参数\n",
    "ansatz_params_history=[] # 记录每个epoch的网络参数\n",
    "best_candidates_history=[] # 记录每个epoch的最佳候选\n",
    "acc_history = [] #记录每个epoch的准确率\n",
    "\n",
    " \n",
    "for epoch in range(epochs):  # 更新结构参数的迭代\n",
    "    avcost2 = avcost1\n",
    "    costl = []\n",
    "    tmp = np.stack([sampling_from_structure(stp,num_layer,shape_parametized) for _ in range(batch_size)])\n",
    "    batch_structure = ops_onehot(ms.Tensor(tmp),shape_parametized+shape_unparameterized,ms.Tensor(1),ms.Tensor(0))\n",
    "    #print(batch_structure.shape)\n",
    "    # print(tmp,batch_structure)\n",
    "    loss_value = []\n",
    "    grad_nnps = []\n",
    "    grad_stps = []\n",
    "    \n",
    "    for i in batch_structure:\n",
    "        #print(ops.Argmax()(i))          \n",
    "        infd, grad_nnp = vag_nnp_micro(Structure_params=i,\n",
    "                                    Ansatz_params=nnp,\n",
    "                                    paramerterized_pool=parameterized_circuit,  unparamerterized_pool=unparameterized_circuit,\n",
    "                                    num_layer=num_layer,n_qbits=8)(ms.Tensor(X_train),ms.Tensor(y_train))\n",
    "        \n",
    "        grad_nnp_zeroslike = zeroslike_grad_nnp_micro(batch_sturcture=i,grad_nnp=grad_nnp[0],shape_parametized=shape_parametized,ansatz_parameters=nnp)\n",
    "        gs = nmf_gradient(structures=stp,oh=i,num_layer=num_layer,size_pool=stp.shape[1])\n",
    "        #print(infd,grad_nnp)\n",
    "        loss_value.append(infd)\n",
    "        grad_nnps.append(ms.Tensor(grad_nnp_zeroslike,dtype=ms.float64))\n",
    "        grad_stps.append(gs)\n",
    "\n",
    "      \n",
    "    infd = ops.stack(loss_value)\n",
    "    gnnp = ops.addn(grad_nnps)\n",
    "    gstp = [(infd[i] - avcost2) * grad_stps[i] for i in range(infd.shape[0])]\n",
    "    gstp_averge = ops.addn(gstp) / infd.shape[0]\n",
    "    avcost1 = sum(infd) / infd.shape[0]\n",
    "    # print(f'loss={infd}\\ngrad_nnp={gnnp}\\ngrandient_stp={gstp_averge}')\n",
    "    \n",
    "    gnnp_tf = tf.convert_to_tensor(gnnp.asnumpy(),dtype=tf.float64)\n",
    "    nnp_tf = tf.convert_to_tensor(nnp,dtype=tf.float64)\n",
    "    gstp_averge_tf = tf.convert_to_tensor(gstp_averge.reshape(stp.shape).asnumpy(),dtype=tf.float64)\n",
    "    stp_tf = tf.convert_to_tensor(stp,dtype=tf.float64)\n",
    "     # 更新参数\n",
    "    nnp_tf = network_opt.update(gnnp_tf, nnp_tf)\n",
    "    stp_tf = structure_opt.update(gstp_averge_tf, stp_tf) \n",
    "    \n",
    "    nnp = nnp_tf.numpy()\n",
    "    stp = stp_tf.numpy()\n",
    "\n",
    "    batch_loss_history.append(avcost1)\n",
    "    structure_distribution_history.append(stp)\n",
    "    ansatz_params_history.append(nnp)\n",
    "    #best_candidates_history.append(best_from_structure(cand_preset.asnumpy()))\n",
    "    cand_preset = best_from_structure(stp)\n",
    "    best_candidates_history.append(cand_preset.asnumpy())\n",
    "    \n",
    "\n",
    "    if epoch % 1 == 0 or epoch == epochs - 1:\n",
    "        print(\"----------epoch %s-----------\" % epoch)\n",
    "        print(\n",
    "            \"batched平均损失: \",\n",
    "            avcost1,\n",
    "        )\n",
    "    \n",
    "        if verbose:\n",
    "            print(\n",
    "                \"strcuture parameter: \\n\",\n",
    "                stp,\n",
    "                \"\\n network parameter: \\n\",\n",
    "                nnp,\n",
    "            )\n",
    "        \n",
    "        print(\"最好的候选结构:\",cand_preset)\n",
    "        stp_for_test = ops_onehot(ms.Tensor(cand_preset),shape_parametized+shape_unparameterized,ms.Tensor(1),ms.Tensor(0))\n",
    "        test_ansatz = Mindspore_ansatz_micro(Structure_p=stp_for_test,\n",
    "                                            parameterized_pool=parameterized_circuit,unparameterized_pool=unparameterized_circuit,\n",
    "                                            num_layer=num_layer,\n",
    "                                            n_qbits=8)\n",
    "        \n",
    "        ansatz_parameters=[]\n",
    "        for each_sub in range(7):\n",
    "            for layerIndex,i in enumerate(cand_preset):\n",
    "                if i >=len(parameterized_circuit):\n",
    "                    continue\n",
    "                else:\n",
    "                    ansatz_parameters.append(nnp[each_sub,layerIndex,i])\n",
    "        \n",
    "        acc = DQAS_accuracy(ansatz=test_ansatz,Network_params=ansatz_parameters,n_qbits=8)\n",
    "        acc_history.append(acc)\n",
    "        print(f'二分类准确率 Acc ={acc*100}% ')\n",
    "        \n",
    "        #我想每一轮结束 保存batch_loss_history、structure_distribution_history、ansatz_params_history、best_candidates_history、acc_history\n",
    "                # 保存数据\n",
    "        with open('training_history-2.pkl', 'wb') as f:\n",
    "            pickle.dump({\n",
    "                'batch_loss_history': batch_loss_history,\n",
    "                'structure_distribution_history': structure_distribution_history,\n",
    "                'ansatz_params_history': ansatz_params_history,\n",
    "                'best_candidates_history': best_candidates_history,\n",
    "                'acc_history': acc_history\n",
    "            }, f)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DQAS_tool import Test_ansatz\n",
    "value = Test_ansatz(ansatz=ansatz,learning_rate=0.1,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('training_history.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ansatz_params_history'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
