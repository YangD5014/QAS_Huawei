{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/Quantum/lib/python3.9/site-packages/mindquantum/simulator/__init__.py:17: UserWarning: Unable import mqvector gpu backend due to: cannot import name '_mq_vector_gpu' from partially initialized module 'mindquantum' (most likely due to a circular import) (/opt/miniconda3/envs/Quantum/lib/python3.9/site-packages/mindquantum/__init__.py)\n",
      "  from .available_simulator import SUPPORTED_SIMULATOR\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mindquantum.core.gates import RX, RY, RZ, H, X, Y, Z, CNOT\n",
    "from mindquantum.core.circuit import Circuit\n",
    "import mindspore as ms\n",
    "from mindquantum.simulator import  Simulator\n",
    "from mindquantum.core.gates import GroupedPauli\n",
    "from mindquantum.core.operators import TimeEvolution,QubitOperator\n",
    "from mindquantum.core.parameterresolver import PRConvertible,PRGenerator,ParameterResolver\n",
    "from DQAS_tool import generate_pauli_string,one_hot\n",
    "from mindquantum.core.gates import RotPauliString\n",
    "from mindquantum.core.gates import UnivMathGate\n",
    "from mindspore import Tensor, ops\n",
    "from mindquantum.core.circuit import UN\n",
    "from mindquantum.core.operators import Hamiltonian             # 导入Hamiltonian模块，用于构建哈密顿量\n",
    "from mindquantum.framework import MQLayer,MQOps\n",
    "from mindspore.nn import  TrainOneStepCell\n",
    "from mindspore.nn import SoftmaxCrossEntropyWithLogits                         # 导入SoftmaxCrossEntropyWithLogits模块，用于定义损失函数\n",
    "from mindspore.nn import Adam                                                  # 导入Adam模块用于定义优化参数\n",
    "from mindspore.train import Accuracy, Model, LossMonitor                       # 导入Accuracy模块，用于评估预测准确率\n",
    "import mindspore as ms\n",
    "from mindspore import Parameter, Tensor\n",
    "from mindspore.dataset import NumpySlicesDataset\n",
    "from torch.utils.data import DataLoader# 导入NumpySlicesDataset模块，用于创建模型可以识别的数据集\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from data_processing import X_train,X_test,y_train,y_test\n",
    "from mindquantum.algorithm.nisq import HardwareEfficientAnsatz     \n",
    "# #Operator Pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "unbound_opeartor_pool = \\\n",
    "[\"X0 X1 I2 I3 I4 I5 I6 I7\", \n",
    " \"I0 X1 X2 I3 I4 I5 I6 I7\",\n",
    " \"I0 I1 X2 X3 I4 I5 I6 I7\",\n",
    " \"I0 I1 I2 X3 X4 I5 I6 I7\",\n",
    " \"I0 I1 I2 I3 X4 X5 I6 I7\",\n",
    " \"I0 I1 I2 I3 I4 I4 X6 I7\",\n",
    " \"Y0 Y1 I2 I3 I4 I4 I6 I7\",\n",
    " \"I0 Y1 Y2 I3 I4 I4 I6 I7\",\n",
    " \"I0 I1 Y2 Y3 I4 I4 I6 I7\",\n",
    " \"I0 I1 I2 Y3 Y4 I4 I6 I7\",\n",
    " \"I0 I1 I2 I3 Y4 Y5 I6 I7\",\n",
    " \"I0 I1 I2 I3 I4 Y5 Y6 I7\",\n",
    " ]\n",
    "bound_opeartor_pool = \\\n",
    "['ZYIXXXZX',\n",
    " 'IZZYYXZI',\n",
    " 'XIIXYIIZ',\n",
    " 'IIIYYIYX',\n",
    " 'IZZYIXZI',\n",
    " 'ZZYYYYYY']\n",
    "\n",
    "num_layer = 7\n",
    "# 定义标准差和形状\n",
    "stddev = 0.02\n",
    "shape_parametized = len(unbound_opeartor_pool)\n",
    "shape_unparametized = len(bound_opeartor_pool)\n",
    "shape_nnp = (num_layer, shape_parametized)\n",
    "shape_stp = (num_layer, shape_parametized+shape_unparametized)\n",
    "\n",
    "nnp = np.random.normal(loc=0.0, scale=stddev, size=shape_nnp)\n",
    "stp = np.random.normal(loc=0.0, scale=stddev, size=shape_stp)\n",
    "\n",
    "np.random.seed(10)\n",
    "unbound_opeartor_pool = [generate_pauli_string(n=8,seed=i)[0] for i in range(shape_parametized)]\n",
    "bound_opeartor_pool = [generate_pauli_string(n=8,seed=i)[1] for i in range(shape_parametized,shape_parametized+shape_unparametized)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DQAS_tool import Mindspore_ansatz2,sampling_from_structure,nmf_gradient,vag_nnp2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ansatz = Mindspore_ansatz2(Structure_p=stp,parameterized_pool=unbound_opeartor_pool,unparameterized_pool=bound_opeartor_pool,num_layer=num_layer,n_qbits=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "ops_onehot = ops.OneHot(axis=-1)\n",
    "tmp = np.stack([sampling_from_structure(stp,num_layer,shape_parametized) for _ in range(batch_size)])\n",
    "batch_structure = ops_onehot(ms.Tensor(tmp),shape_parametized+shape_unparametized,ms.Tensor(1),ms.Tensor(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  8,  1,  7, 14, 17, 12])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_structure[0]\n",
    "tmp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "6\n",
      "12\n",
      "8\n",
      "7\n",
      "11\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for each_layer in batch_structure[0]:\n",
    "    # print(each_layer)\n",
    "    print(ops.Argmax()(each_layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 12)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ansatz0', 'ansatz1', 'ansatz2', 'ansatz3']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ansatz = Mindspore_ansatz2(Structure_p=batch_structure[0],parameterized_pool=unbound_opeartor_pool,unparameterized_pool=bound_opeartor_pool,num_layer=num_layer,n_qbits=8)\n",
    "ansatz.ansatz_params_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tensor(shape=[], dtype=Int32, value= 2), Tensor(shape=[], dtype=Int32, value= 10), Tensor(shape=[], dtype=Int32, value= 4), Tensor(shape=[], dtype=Int32, value= 11), Tensor(shape=[], dtype=Int32, value= 9), Tensor(shape=[], dtype=Int32, value= 7), Tensor(shape=[], dtype=Int32, value= 11)]\n",
      "[0.04090865878616149, 0.025358561448930717, 0.0361049252974905, 0.042638790534355445, 0.03013244989482282, 0.022747611188208956, 0.03221753341251426]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Weight init shape error, required (4, ), but get (7,).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[43mvag_nnp2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mStructure_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_structure\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mAnsatz_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnnp\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparamerterized_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munbound_opeartor_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43munparamerterized_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbound_opeartor_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn_qbits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/vscode/Huawei-QAS/DQAS/DQAS_tool.py:281\u001b[0m, in \u001b[0;36mvag_nnp2\u001b[0;34m(Structure_params, Ansatz_params, paramerterized_pool, unparamerterized_pool, num_layer, n_qbits)\u001b[0m\n\u001b[1;32m    278\u001b[0m ansatz_parameters \u001b[38;5;241m=\u001b[39m [Ansatz_params[layer_index][i] \u001b[38;5;28;01mfor\u001b[39;00m layer_index,i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(nnp_index)]\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28mprint\u001b[39m(ansatz_parameters)\n\u001b[0;32m--> 281\u001b[0m Mylayer \u001b[38;5;241m=\u001b[39m \u001b[43mMQLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_ops\u001b[49m\u001b[43m,\u001b[49m\u001b[43mms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mansatz_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43mms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fn\u001b[39m(encode_p,y_label):\n\u001b[1;32m    285\u001b[0m     eval_obserables \u001b[38;5;241m=\u001b[39m Mylayer(encode_p)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/Quantum/lib/python3.9/site-packages/mindquantum/framework/layer.py:89\u001b[0m, in \u001b[0;36mMQLayer.__init__\u001b[0;34m(self, expectation_with_grad, weight)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(weight, ms\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weight\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m weight\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m weight_size:\n\u001b[0;32m---> 89\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeight init shape error, required (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, ), but get \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m Parameter(initializer(weight, weight_size, dtype\u001b[38;5;241m=\u001b[39mms\u001b[38;5;241m.\u001b[39mfloat32), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mansatz_weight\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Weight init shape error, required (4, ), but get (7,)."
     ]
    }
   ],
   "source": [
    "g = vag_nnp2(Structure_params=batch_structure[0],Ansatz_params=nnp,paramerterized_pool=unbound_opeartor_pool,unparamerterized_pool=bound_opeartor_pool,num_layer=num_layer,n_qbits=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ansatz = Mindspore_ansatz2(Structure_p=batch_structure[3],parameterized_pool=unbound_opeartor_pool,unparameterized_pool=bound_opeartor_pool,num_layer=num_layer,n_qbits=8)\n",
    "\n",
    "gs = nmf_gradient(structures=stp,oh=batch_structure[0],num_layer=num_layer,size_pool=shape_parametized+shape_unparametized)\n",
    "gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ansatz.ansatz_params_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorcircuit as tc\n",
    "import tensorflow as tf\n",
    "from DQAS_tool import  DQASAnsatz_from_result,vag_nnp,nmf_gradient\n",
    "K = tc.set_backend(\"tensorflow\")\n",
    "lr = tf.keras.optimizers.schedules.ExponentialDecay(0.06, 100, 0.5)\n",
    "structure_opt = tc.backend.optimizer(tf.keras.optimizers.Adam(0.05))\n",
    "network_opt = tc.backend.optimizer(tf.keras.optimizers.Adam(lr))\n",
    "verbose = False\n",
    "# 设置超参数\n",
    "epochs = 100\n",
    "batch_size=256\n",
    "# shape_nnp = (num_layer, shape_parametized)\n",
    "# shape_stp = (num_layer, shape_parametized+7)\n",
    "# nnp = np.random.normal(loc=0.0, scale=stddev, size=shape_nnp).astype(rtype)\n",
    "# stp = np.random.normal(loc=0.0, scale=stddev, size=shape_stp).astype(rtype)\n",
    "print('sdsd',stp.shape)\n",
    "avcost1 = 0\n",
    "\n",
    "ops_onehot = ops.OneHot(axis=-1)\n",
    "\n",
    "avcost2 = avcost1\n",
    "\n",
    "costl = []\n",
    "tmp = np.stack([sampling_from_structure(stp,num_layer,shape_parametized) for _ in range(batch_size)])\n",
    "batch_structure = ops_onehot(ms.Tensor(tmp),shape_parametized+shape_unparametized,ms.Tensor(1),ms.Tensor(0))\n",
    "#print(batch_structure.shape)\n",
    "# print(tmp,batch_structure)\n",
    "loss_value = []\n",
    "grad_nnps = []\n",
    "grad_stps = []\n",
    "    \n",
    "for i in batch_structure:          \n",
    "    infd, grad_nnp = vag_nnp(Structure_params=i,Ansatz_params=nnp,paramerterized_pool=unbound_opeartor_pool,unparamterized_pool=bound_opeartor_pool,num_layer=num_layer,n_qbits=8)(ms.Tensor(X_train),ms.Tensor(y_train))\n",
    "    gs = nmf_gradient(structures=stp,oh=i,num_layer=num_layer,size_pool=shape_parametized+shape_unparametized)\n",
    "    #print(infd,grad_nnp)\n",
    "    loss_value.append(infd)\n",
    "    grad_nnps.append(grad_nnp[0])\n",
    "    grad_stps.append(gs)\n",
    "\n",
    "infd = ops.stack(loss_value)\n",
    "gnnp = ops.addn(grad_nnps)\n",
    "gstp = [(infd[i] - avcost2) * grad_stps[i] for i in range(infd.shape[0])]\n",
    "gstp_averge = ops.addn(gstp) / infd.shape[0]\n",
    "avcost1 = sum(infd) / infd.shape[0]\n",
    "\n",
    "    \n",
    "print(gstp_averge)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Quantum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
