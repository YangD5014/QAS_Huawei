{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/MindSpore/lib/python3.9/site-packages/mindquantum/simulator/__init__.py:17: UserWarning: Unable import mqvector gpu backend due to: cannot import name '_mq_vector_gpu' from partially initialized module 'mindquantum' (most likely due to a circular import) (/opt/miniconda3/envs/MindSpore/lib/python3.9/site-packages/mindquantum/__init__.py)\n",
      "  from .available_simulator import SUPPORTED_SIMULATOR\n",
      "Please first ``pip install -U qiskit`` to enable related functionality in translation module\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mindspore import Tensor, ops\n",
    "import mindspore as ms\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from data_processing import X_train,X_test,y_train,y_test\n",
    "from DQAS_tool import Mindspore_ansatz3,vag_nnp3,sampling_from_structure,nmf_gradient,zeroslike_grad_nnp,generate_pauli_string\n",
    "import numpy as np\n",
    "import json\n",
    "import tensorcircuit as tc\n",
    "import tensorflow as tf\n",
    "from DQAS_tool import best_from_structure,DQAS_accuracy\n",
    "from mindquantum.core.operators import TimeEvolution,QubitOperator\n",
    "from mindquantum.core.parameterresolver import PRGenerator\n",
    "from mindquantum.core.circuit import change_param_name,UN\n",
    "from mindquantum.core.gates import RX, RY, RZ, H, X, Y, Z, CNOT\n",
    "# #Operator Pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pauli_ops=\\\n",
    "['X0 X1','X1 X2','X3 X4','X4 X5','X6 X7','X7 X0',\n",
    " 'Y0 Y1','Y1 Y2','Y3 Y4','Y4 Y5','Y6 Y7','Y7 Y0',\n",
    " 'Z0 Z1','Z1 Z2','Z3 Z4','Z4 Z5','Z6 Z7','Z7 Z0',\\\n",
    " 'X0 Y1 Z2 X3','Y1 Z2 X3 X4']\n",
    "\n",
    "unparameterized_circuit = \\\n",
    "[UN(Z, maps_obj = [0,1,2,3], maps_ctrl = [4,5,6,7]),\n",
    " UN(Z, maps_obj = [4,5,6,7], maps_ctrl = [0,1,2,3]),\n",
    " UN(X, maps_obj = [0,1,2,3], maps_ctrl = [4,5,6,7]),\n",
    " UN(X, maps_obj = [4,5,6,7], maps_ctrl = [0,1,2,3]),\n",
    " UN(Y, maps_obj = [0,1,2,3], maps_ctrl = [4,5,6,7]),\n",
    " UN(Y, maps_obj = [4,5,6,7], maps_ctrl = [0,1,2,3]),\n",
    " ]\n",
    "ansatz_pr = PRGenerator('ansatz')\n",
    "parameterized_circuit=[TimeEvolution(QubitOperator(i,ansatz_pr.new()),time=0.5).circuit for i in Pauli_ops]\n",
    "shape_parametized = len(parameterized_circuit)\n",
    "shape_unparameterized = len(unparameterized_circuit)\n",
    "num_layer=12\n",
    "shape_nnp = (num_layer,shape_parametized)\n",
    "shape_stp = (num_layer,shape_unparameterized+shape_parametized)\n",
    "stddev = 0.03\n",
    "nnp = np.random.normal(loc=0.0, scale=stddev, size=shape_nnp)\n",
    "stp = np.random.normal(loc=0.0, scale=stddev, size=shape_stp)\n",
    "ops_onehot = ops.OneHot(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_from_structure(structures: np.array)->Tensor:\n",
    "    prob = ops.Softmax()(ms.Tensor(structures))\n",
    "    return ops.Argmax(axis=-1)(prob)\n",
    "\n",
    "def best_from_structure(structures: np.array)->Tensor:\n",
    "    return ops.Argmax(axis=-1)(ms.Tensor(structures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------epoch 0-----------\n",
      "batched平均损失:  0.6543136\n",
      "最好的候选结构: [11 23  5 19  3 15 14 10 24 11 22  4]\n",
      "二分类准确率 Acc =64.17445482866043% \n",
      "----------epoch 1-----------\n",
      "batched平均损失:  0.6534667\n",
      "最好的候选结构: [25 23  5  8  3 15 14 10 24 11 22 23]\n",
      "二分类准确率 Acc =64.58982346832815% \n",
      "----------epoch 2-----------\n",
      "batched平均损失:  0.6533463\n",
      "最好的候选结构: [25 23  5 14  5 15 14 10 24  4 22 23]\n",
      "二分类准确率 Acc =64.17445482866043% \n",
      "----------epoch 3-----------\n",
      "batched平均损失:  0.65582854\n",
      "最好的候选结构: [25 23  5 14  5 15 14 10  0  4 13 23]\n",
      "二分类准确率 Acc =64.17445482866043% \n",
      "----------epoch 4-----------\n",
      "batched平均损失:  0.6504194\n",
      "最好的候选结构: [25 23  5 14  5 15 14 10  0  4 13 23]\n",
      "二分类准确率 Acc =64.17445482866043% \n",
      "----------epoch 5-----------\n",
      "batched平均损失:  0.6526827\n",
      "最好的候选结构: [25 21  8 14  5  7 14 10  0 11 13 23]\n",
      "二分类准确率 Acc =65.10903426791276% \n",
      "----------epoch 6-----------\n",
      "batched平均损失:  0.6469898\n",
      "最好的候选结构: [25 21  8 14  5  7  5 10  0 11 18  2]\n",
      "二分类准确率 Acc =66.66666666666666% \n",
      "----------epoch 7-----------\n",
      "batched平均损失:  0.64494103\n",
      "最好的候选结构: [25 21  8 14  5  7  5 10  0 11 18  2]\n",
      "二分类准确率 Acc =68.01661474558671% \n",
      "----------epoch 8-----------\n",
      "batched平均损失:  0.64815044\n",
      "最好的候选结构: [25 19  8 10  5  7  5 10  0 11 18 23]\n",
      "二分类准确率 Acc =67.70508826583594% \n",
      "----------epoch 9-----------\n",
      "batched平均损失:  0.6454259\n",
      "最好的候选结构: [25 25  8 14  5  7  5 10  0 11 18 23]\n",
      "二分类准确率 Acc =65.73208722741433% \n",
      "----------epoch 10-----------\n",
      "batched平均损失:  0.6442025\n",
      "最好的候选结构: [25 25  8 14  5  7  5 12  0 11 18 23]\n",
      "二分类准确率 Acc =64.48598130841121% \n",
      "----------epoch 11-----------\n",
      "batched平均损失:  0.6447482\n",
      "最好的候选结构: [25 25  8 14  5  7  5 12  0 11 18 23]\n",
      "二分类准确率 Acc =63.2398753894081% \n",
      "----------epoch 12-----------\n",
      "batched平均损失:  0.64054114\n",
      "最好的候选结构: [25 25  8 14  5  7  5 12  0 11 18 23]\n",
      "二分类准确率 Acc =62.616822429906534% \n",
      "----------epoch 13-----------\n",
      "batched平均损失:  0.6417199\n",
      "最好的候选结构: [25 25  8 14  5 11  5 12  0 11 18 23]\n",
      "二分类准确率 Acc =52.85565939771547% \n",
      "----------epoch 14-----------\n",
      "batched平均损失:  0.63836133\n",
      "最好的候选结构: [25 25 11 10  5 11  5 12  8 11 11 23]\n",
      "二分类准确率 Acc =70.19730010384217% \n",
      "----------epoch 15-----------\n",
      "batched平均损失:  0.6338085\n",
      "最好的候选结构: [25 25 11 10  5 11  5 12  8 11 11  6]\n",
      "二分类准确率 Acc =71.44340602284528% \n",
      "----------epoch 16-----------\n",
      "batched平均损失:  0.6363114\n",
      "最好的候选结构: [25 25 11 10  5 11  5 12  8 11 11  6]\n",
      "二分类准确率 Acc =70.82035306334372% \n",
      "----------epoch 17-----------\n",
      "batched平均损失:  0.6351577\n",
      "最好的候选结构: [25 25 11 10  5 11  5 12  8 11 11  6]\n",
      "二分类准确率 Acc =71.33956386292834% \n",
      "----------epoch 18-----------\n",
      "batched平均损失:  0.63123643\n",
      "最好的候选结构: [23 25 11 10  5 11  5 12  8 11 11  6]\n",
      "二分类准确率 Acc =70.92419522326064% \n",
      "----------epoch 19-----------\n",
      "batched平均损失:  0.63371456\n",
      "最好的候选结构: [23 25 11 10  5 11  5 12  0 11 11  6]\n",
      "二分类准确率 Acc =70.61266874350987% \n",
      "----------epoch 20-----------\n",
      "batched平均损失:  0.63268644\n",
      "最好的候选结构: [23 25 11 10  5 11  5 12 21 11 11  6]\n",
      "二分类准确率 Acc =70.19730010384217% \n",
      "----------epoch 21-----------\n",
      "batched平均损失:  0.63479644\n",
      "最好的候选结构: [23 25 11 10  5 11  5 12 21 11 11  6]\n",
      "二分类准确率 Acc =70.7165109034268% \n",
      "----------epoch 22-----------\n",
      "batched平均损失:  0.6301214\n",
      "最好的候选结构: [23 25 11 10  5 11  5 12 21 11 11  6]\n",
      "二分类准确率 Acc =70.92419522326064% \n",
      "----------epoch 23-----------\n",
      "batched平均损失:  0.63041174\n",
      "最好的候选结构: [23 25 11 10  5 11  5 12 21 11 11  6]\n",
      "二分类准确率 Acc =70.61266874350987% \n",
      "----------epoch 24-----------\n",
      "batched平均损失:  0.6289528\n",
      "最好的候选结构: [23 25 11 10  5 11  5 12 21 11 11  6]\n",
      "二分类准确率 Acc =70.92419522326064% \n",
      "----------epoch 25-----------\n",
      "batched平均损失:  0.631812\n",
      "最好的候选结构: [ 5 25 11 10  5 11  5 12 21 11 11  6]\n",
      "二分类准确率 Acc =69.47040498442367% \n",
      "----------epoch 26-----------\n",
      "batched平均损失:  0.6273035\n",
      "最好的候选结构: [ 5 25 11 10  5 11  5 12 21 11 11  6]\n",
      "二分类准确率 Acc =69.47040498442367% \n",
      "----------epoch 27-----------\n",
      "batched平均损失:  0.62924665\n",
      "最好的候选结构: [ 5 25 11 10  5 11  5 12 21 11 11  6]\n",
      "二分类准确率 Acc =69.26272066458982% \n",
      "----------epoch 28-----------\n",
      "batched平均损失:  0.62450707\n",
      "最好的候选结构: [ 5 25 11 10  5 11  5 12 21 11 11  6]\n",
      "二分类准确率 Acc =69.26272066458982% \n",
      "----------epoch 29-----------\n",
      "batched平均损失:  0.62780774\n",
      "最好的候选结构: [ 5 25 11 10  5 11  5 12 21 11 11  6]\n",
      "二分类准确率 Acc =69.26272066458982% \n",
      "----------epoch 30-----------\n",
      "batched平均损失:  0.6271233\n",
      "最好的候选结构: [ 5 25 11 10  5 11  5 12 21 11 11  6]\n",
      "二分类准确率 Acc =69.26272066458982% \n",
      "----------epoch 31-----------\n",
      "batched平均损失:  0.62421846\n",
      "最好的候选结构: [ 5 25 11 10  5 11  5 12 21 11 11  6]\n",
      "二分类准确率 Acc =69.26272066458982% \n",
      "----------epoch 32-----------\n",
      "batched平均损失:  0.62400997\n",
      "最好的候选结构: [ 5 25 11 10  5 11  5 12 21 11 11  6]\n",
      "二分类准确率 Acc =69.5742471443406% \n",
      "----------epoch 33-----------\n",
      "batched平均损失:  0.6245826\n",
      "最好的候选结构: [ 5 25 11 10  5 11 23 12 21 11 11  6]\n",
      "二分类准确率 Acc =69.5742471443406% \n",
      "----------epoch 34-----------\n",
      "batched平均损失:  0.6188256\n",
      "最好的候选结构: [ 5  5 11 10  5 11 23 12 21 11 11  6]\n",
      "二分类准确率 Acc =69.26272066458982% \n",
      "----------epoch 35-----------\n",
      "batched平均损失:  0.6237944\n",
      "最好的候选结构: [ 5  5 11 10  5 11 23 12 21 11 11  6]\n",
      "二分类准确率 Acc =69.1588785046729% \n",
      "----------epoch 36-----------\n",
      "batched平均损失:  0.6223997\n",
      "最好的候选结构: [ 5  5 11 10  5 11 23 12 21 11 11  6]\n",
      "二分类准确率 Acc =69.1588785046729% \n",
      "----------epoch 37-----------\n",
      "batched平均损失:  0.6204359\n",
      "最好的候选结构: [ 5  5 11 10  5 11 23 12 21 11 11  6]\n",
      "二分类准确率 Acc =69.1588785046729% \n",
      "----------epoch 38-----------\n",
      "batched平均损失:  0.6179825\n",
      "最好的候选结构: [ 5  5 11 10  5 11 16 12 21 11 11  6]\n",
      "二分类准确率 Acc =69.47040498442367% \n",
      "----------epoch 39-----------\n",
      "batched平均损失:  0.6183352\n",
      "最好的候选结构: [ 5  5 11 10  5 11 16 12 21 11 11  6]\n",
      "二分类准确率 Acc =69.26272066458982% \n",
      "----------epoch 40-----------\n",
      "batched平均损失:  0.6130313\n",
      "最好的候选结构: [ 5  5 11 10  5 11 16 12 21 11 11  6]\n",
      "二分类准确率 Acc =69.05503634475598% \n",
      "----------epoch 41-----------\n",
      "batched平均损失:  0.61537\n",
      "最好的候选结构: [ 5  5 11 10  5 11 16 12 21 11 11  6]\n",
      "二分类准确率 Acc =69.26272066458982% \n",
      "----------epoch 42-----------\n",
      "batched平均损失:  0.6141764\n",
      "最好的候选结构: [ 5  5 11 10  5 11 16 12 21 11 11  6]\n",
      "二分类准确率 Acc =69.1588785046729% \n",
      "----------epoch 43-----------\n",
      "batched平均损失:  0.6140643\n",
      "最好的候选结构: [ 5  5 11 10  5 11  6 12 21 11 11  6]\n",
      "二分类准确率 Acc =69.26272066458982% \n",
      "----------epoch 44-----------\n",
      "batched平均损失:  0.6150768\n",
      "最好的候选结构: [ 5  5 11 10  5 11  6 12 21 11 11  6]\n",
      "二分类准确率 Acc =69.36656282450674% \n",
      "----------epoch 45-----------\n",
      "batched平均损失:  0.6120986\n",
      "最好的候选结构: [ 5  5 11 10  5 11  6 12 21 11 11  6]\n",
      "二分类准确率 Acc =69.36656282450674% \n",
      "----------epoch 46-----------\n",
      "batched平均损失:  0.60800457\n",
      "最好的候选结构: [ 5  5 11 10  5 11  6 12 21 11 11  6]\n",
      "二分类准确率 Acc =69.36656282450674% \n",
      "----------epoch 47-----------\n",
      "batched平均损失:  0.6098433\n",
      "最好的候选结构: [ 5  5 11 10  5 11  6 12 21 11 11  6]\n",
      "二分类准确率 Acc =68.95119418483905% \n",
      "----------epoch 48-----------\n",
      "batched平均损失:  0.6094839\n",
      "最好的候选结构: [ 5  5 11 10  5 11  6 12 21 11 11  6]\n",
      "二分类准确率 Acc =69.05503634475598% \n",
      "----------epoch 49-----------\n",
      "batched平均损失:  0.60733706\n",
      "最好的候选结构: [ 5  5 11 10  5 11  6 12 21 11 11  6]\n",
      "二分类准确率 Acc =69.26272066458982% \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#from DQAS_tool import  DQASAnsatz_from_result,DQAS_accuracy\n",
    "K = tc.set_backend(\"tensorflow\")\n",
    "lr = tf.keras.optimizers.schedules.ExponentialDecay(0.06, 100, 0.5)\n",
    "structure_opt = tc.backend.optimizer(tf.keras.optimizers.Adam(0.1))\n",
    "network_opt = tc.backend.optimizer(tf.keras.optimizers.Adam(lr))\n",
    "verbose = False\n",
    "# 设置超参数\n",
    "epochs = 50\n",
    "batch_size=256\n",
    "avcost1 = 0\n",
    "ops_onehot = ops.OneHot(axis=-1)\n",
    "batch_loss_history=[] # 记录每个epoch的batch_size损失值\n",
    "structure_distribution_history=[] # 记录每个epoch的结构参数\n",
    "ansatz_params_history=[] # 记录每个epoch的网络参数\n",
    "best_candidates_history=[] # 记录每个epoch的最佳候选\n",
    "acc_history = [] #记录每个epoch的准确率\n",
    "\n",
    " \n",
    "for epoch in range(epochs):  # 更新结构参数的迭代\n",
    "    avcost2 = avcost1\n",
    "    costl = []\n",
    "    tmp = np.stack([sampling_from_structure(stp,num_layer,shape_parametized) for _ in range(batch_size)])\n",
    "    batch_structure = ops_onehot(ms.Tensor(tmp),shape_parametized+shape_unparameterized,ms.Tensor(1),ms.Tensor(0))\n",
    "    #print(batch_structure.shape)\n",
    "    # print(tmp,batch_structure)\n",
    "    loss_value = []\n",
    "    grad_nnps = []\n",
    "    grad_stps = []\n",
    "    \n",
    "    for i in batch_structure:\n",
    "        #print(ops.Argmax()(i))          \n",
    "        infd, grad_nnp = vag_nnp3(Structure_params=i,\n",
    "                                  Ansatz_params=nnp,\n",
    "                                  paramerterized_pool=parameterized_circuit,unparamerterized_pool=unparameterized_circuit,\n",
    "                                  num_layer=num_layer,n_qbits=8)(ms.Tensor(X_train),ms.Tensor(y_train))\n",
    "        \n",
    "        grad_nnp_zeroslike = zeroslike_grad_nnp(batch_sturcture=i,grad_nnp=grad_nnp[0],shape_parametized=shape_parametized,ansatz_parameters=nnp)\n",
    "        gs = nmf_gradient(structures=stp,oh=i,num_layer=num_layer,size_pool=stp.shape[1])\n",
    "        #print(infd,grad_nnp)\n",
    "        loss_value.append(infd)\n",
    "        grad_nnps.append(ms.Tensor(grad_nnp_zeroslike,dtype=ms.float64))\n",
    "        grad_stps.append(gs)\n",
    "\n",
    "      \n",
    "    infd = ops.stack(loss_value)\n",
    "    gnnp = ops.addn(grad_nnps)\n",
    "    gstp = [(infd[i] - avcost2) * grad_stps[i] for i in range(infd.shape[0])]\n",
    "    gstp_averge = ops.addn(gstp) / infd.shape[0]\n",
    "    avcost1 = sum(infd) / infd.shape[0]\n",
    "    # print(f'loss={infd}\\ngrad_nnp={gnnp}\\ngrandient_stp={gstp_averge}')\n",
    "    \n",
    "    gnnp_tf = tf.convert_to_tensor(gnnp.asnumpy(),dtype=tf.float64)\n",
    "    nnp_tf = tf.convert_to_tensor(nnp,dtype=tf.float64)\n",
    "    gstp_averge_tf = tf.convert_to_tensor(gstp_averge.reshape(stp.shape).asnumpy(),dtype=tf.float64)\n",
    "    stp_tf = tf.convert_to_tensor(stp,dtype=tf.float64)\n",
    "     # 更新参数\n",
    "    nnp_tf = network_opt.update(gnnp_tf, nnp_tf)\n",
    "    stp_tf = structure_opt.update(gstp_averge_tf, stp_tf) \n",
    "    \n",
    "    nnp = nnp_tf.numpy()\n",
    "    stp = stp_tf.numpy()\n",
    "\n",
    "    batch_loss_history.append(avcost1)\n",
    "    structure_distribution_history.append(stp)\n",
    "    ansatz_params_history.append(nnp)\n",
    "    #best_candidates_history.append(best_from_structure(cand_preset.asnumpy()))\n",
    "    cand_preset = best_from_structure(stp)\n",
    "    best_candidates_history.append(cand_preset.asnumpy())\n",
    "    \n",
    "\n",
    "    if epoch % 1 == 0 or epoch == epochs - 1:\n",
    "        print(\"----------epoch %s-----------\" % epoch)\n",
    "        print(\n",
    "            \"batched平均损失: \",\n",
    "            avcost1,\n",
    "        )\n",
    "    \n",
    "        if verbose:\n",
    "            print(\n",
    "                \"strcuture parameter: \\n\",\n",
    "                stp,\n",
    "                \"\\n network parameter: \\n\",\n",
    "                nnp,\n",
    "            )\n",
    "        \n",
    "        print(\"最好的候选结构:\",cand_preset)\n",
    "        stp_for_test = ops_onehot(ms.Tensor(cand_preset),shape_parametized+shape_unparameterized,ms.Tensor(1),ms.Tensor(0))\n",
    "        test_ansatz = Mindspore_ansatz3(Structure_p=stp_for_test,\n",
    "                                        parameterized_pool=parameterized_circuit,unparameterized_pool=unparameterized_circuit,\n",
    "                                        num_layer=num_layer,\n",
    "                                        n_qbits=8)\n",
    "        \n",
    "        ansatz_parameters=[]\n",
    "        for layerIndex,i in enumerate(cand_preset):\n",
    "            if i >=len(parameterized_circuit):\n",
    "                continue\n",
    "            else:\n",
    "                ansatz_parameters.append(nnp[layerIndex,i])\n",
    "        \n",
    "        acc = DQAS_accuracy(ansatz=test_ansatz,Network_params=ansatz_parameters,n_qbits=8)\n",
    "        acc_history.append(acc)\n",
    "        print(f'二分类准确率 Acc ={acc*100}% ')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.17760695, -1.89972827, -1.27134663, -2.83258734, -0.35378614,\n",
       "         4.18814072, -2.60725566, -1.99444165, -1.51320048, -1.55333361,\n",
       "        -0.68687203,  0.38891093, -1.71106915, -0.68653501, -1.21834353,\n",
       "        -2.17541223, -0.94187029, -0.09086947, -2.81082995, -0.73656952,\n",
       "        -3.57193257, -1.34947882, -2.50586083,  0.13229891, -3.60354208,\n",
       "        -0.07253203],\n",
       "       [ 0.40844915,  0.59206749,  0.68323487,  0.58222385, -0.54116583,\n",
       "         1.36247507, -1.72570766,  0.70830027, -0.84767879, -0.64351788,\n",
       "         0.60192883, -0.42996865,  1.35014244, -0.95767841, -0.73856015,\n",
       "         0.32048661,  1.22358609,  0.40423002, -0.63586893,  0.81879309,\n",
       "        -0.57868509,  0.95717076, -0.9666075 ,  0.82120449, -1.18295046,\n",
       "         1.35780089],\n",
       "       [ 0.45400286, -0.78858699, -1.38317738, -1.23316356, -0.89975035,\n",
       "         1.00106321,  0.54570557,  0.84520363,  0.92947627, -1.51153631,\n",
       "        -0.74050868,  1.63690498,  0.72672263,  0.57446498,  0.22012003,\n",
       "        -0.89200881, -0.74471788, -1.01656649, -0.50625586,  0.41590688,\n",
       "        -0.69977553,  0.02260979, -2.20258388, -0.55107979, -1.23434953,\n",
       "         0.91766933],\n",
       "       [ 0.29961446, -0.6499244 ,  0.16975671, -0.67454094, -0.79139962,\n",
       "        -0.67655959, -1.19698407,  0.54550919,  0.07902861,  0.51212132,\n",
       "         2.62922225,  0.70678525,  0.96585454, -0.78225293,  0.82020548,\n",
       "         2.04038961,  0.26057656, -0.79171006,  0.65822761,  0.1570039 ,\n",
       "        -0.65462151, -1.26683478, -1.15860312, -0.53482093, -0.47546074,\n",
       "        -0.89629698],\n",
       "       [ 0.41375167, -0.61848953, -1.19455524,  0.26606213, -0.90286005,\n",
       "         1.27152008, -1.43429244,  0.80934537,  0.53049056,  0.54913535,\n",
       "         0.50770737, -0.63330198, -0.45443827, -0.68915617,  0.4117858 ,\n",
       "        -0.40134709, -0.53367034,  0.71890977, -0.72000571, -0.87285134,\n",
       "         0.91126842, -1.43856115, -1.12352271,  0.82101536, -2.98104353,\n",
       "        -0.88120028],\n",
       "       [ 0.61980528, -0.58731476,  0.60811316, -0.75647155,  0.09488743,\n",
       "        -0.32487291, -0.96006892,  0.66696061, -0.72431946,  0.38770161,\n",
       "        -0.55555778,  2.16420567,  0.00919008, -1.44665598,  0.53094814,\n",
       "         1.01450996, -0.89620147, -0.76727782,  0.30898523,  0.43121921,\n",
       "        -0.57016758,  1.22492004, -1.96012295, -0.73522512, -0.97933641,\n",
       "        -0.80139628],\n",
       "       [-0.59348081,  0.68163152, -0.63518982,  0.22697786, -0.8139647 ,\n",
       "         0.84341702,  1.19222036, -0.83626557,  0.27717137, -0.7692705 ,\n",
       "        -0.80690123, -0.56566759, -0.58712365, -0.5395031 ,  1.02948304,\n",
       "         1.00421567,  1.06453573,  0.34273358,  0.60786072, -0.76615379,\n",
       "        -0.5321774 , -0.40996102, -1.30087292,  0.94544422, -1.25537066,\n",
       "         0.48041829],\n",
       "       [ 0.19736844, -0.54241361, -0.60070744, -0.72625049, -1.5253615 ,\n",
       "         0.92884502,  0.58937112, -0.64261578, -0.73356257, -0.19330222,\n",
       "         0.69461577, -0.58506508,  1.57743697,  0.85110941, -0.82726257,\n",
       "         1.09502167,  0.78050588,  0.42531164, -0.67458478, -0.62265244,\n",
       "         0.35808277,  0.0416386 , -1.04404261,  0.21054464, -1.41806282,\n",
       "        -0.766378  ],\n",
       "       [ 0.57238259,  0.54246576, -0.21632543, -0.60029323, -0.58267181,\n",
       "        -0.14183893, -0.95197223,  0.49523239, -0.06334474, -0.52111116,\n",
       "         0.97437516, -0.47972287, -0.42182844, -0.76923466, -0.75685381,\n",
       "         1.23877447,  0.72972313, -0.66842735,  0.71571573, -0.98684632,\n",
       "        -0.60668032,  1.75973403, -1.07323941,  0.65116279, -1.37551069,\n",
       "        -0.46887862],\n",
       "       [-0.95630241,  0.59279254, -1.53312922,  0.19560574,  0.0619509 ,\n",
       "        -0.77522357,  0.55263828,  0.35215086,  0.42970843, -1.27068541,\n",
       "        -0.86468965,  2.82442569,  0.21510639, -1.34085263, -1.58216702,\n",
       "        -0.01582479, -1.21929885,  0.48855133, -1.27334035, -0.15701346,\n",
       "        -0.74061958, -0.10403087, -3.11320579,  0.43599639, -3.18765954,\n",
       "        -0.68857206],\n",
       "       [ 0.29521866, -1.14919104, -0.7256131 ,  0.16955538, -0.81047561,\n",
       "         0.47828735,  0.41557052,  0.56136763, -0.97979396,  0.36943361,\n",
       "        -1.43332076,  1.92696239,  0.75021212,  0.78897722, -0.67907204,\n",
       "        -0.80743428, -0.55429482,  0.33542132,  0.7017796 , -0.64172734,\n",
       "         0.01529334, -1.03104791, -1.00209138, -0.71827594, -2.24852382,\n",
       "         0.02533901],\n",
       "       [-0.93699129, -0.28409498,  0.10767106, -0.55071332,  0.60647744,\n",
       "        -0.17097269,  1.59962537,  0.72734983, -0.85804554,  0.39970272,\n",
       "        -1.69697146,  1.17198522,  0.3011711 , -0.04763316, -0.69621011,\n",
       "         0.4788635 ,  0.4703146 , -0.67271179,  0.51333875,  0.54404251,\n",
       "        -2.41846638, -0.75015586, -1.03720571,  0.81262339, -1.36989498,\n",
       "         0.8028877 ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structure_distribution_history[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
