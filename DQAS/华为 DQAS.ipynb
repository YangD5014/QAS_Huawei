{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/MindSpore/lib/python3.9/site-packages/mindquantum/simulator/__init__.py:17: UserWarning: Unable import mqvector gpu backend due to: cannot import name '_mq_vector_gpu' from partially initialized module 'mindquantum' (most likely due to a circular import) (/opt/miniconda3/envs/MindSpore/lib/python3.9/site-packages/mindquantum/__init__.py)\n",
      "  from .available_simulator import SUPPORTED_SIMULATOR\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mindquantum.core.gates import RX, RY, RZ, H, X, Y, Z, CNOT\n",
    "from mindquantum.core.circuit import Circuit\n",
    "import mindspore as ms\n",
    "from mindquantum.simulator import  Simulator\n",
    "from mindquantum.core.gates import GroupedPauli\n",
    "from mindquantum.core.operators import TimeEvolution,QubitOperator\n",
    "from mindquantum.core.parameterresolver import PRConvertible,PRGenerator,ParameterResolver\n",
    "from DQAS_tool import generate_pauli_string\n",
    "from mindquantum.core.gates import RotPauliString\n",
    "from mindquantum.core.gates import UnivMathGate\n",
    "from mindspore import Tensor, ops\n",
    "from mindquantum.core.circuit import UN\n",
    "from mindquantum.core.operators import Hamiltonian             # 导入Hamiltonian模块，用于构建哈密顿量\n",
    "from mindquantum.framework import MQLayer\n",
    "from mindspore.nn import  TrainOneStepCell\n",
    "from mindspore.nn import SoftmaxCrossEntropyWithLogits                         # 导入SoftmaxCrossEntropyWithLogits模块，用于定义损失函数\n",
    "from mindspore.nn import Adam                                                  # 导入Adam模块用于定义优化参数\n",
    "from mindspore.train import Accuracy, Model, LossMonitor                       # 导入Accuracy模块，用于评估预测准确率\n",
    "import mindspore as ms\n",
    "from mindspore.dataset import NumpySlicesDataset\n",
    "from torch.utils.data import DataLoader# 导入NumpySlicesDataset模块，用于创建模型可以识别的数据集\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from data_processing import X_train,X_test,y_train,y_test\n",
    "num_layer = 3\n",
    "# 定义标准差和形状\n",
    "stddev = 0.02\n",
    "shape_nnp = (num_layer, 8)\n",
    "shape_stp = (num_layer, 12)\n",
    "\n",
    "rtype = np.float64\n",
    "ctype = np.complex128\n",
    "# 使用 numpy 生成随机数矩阵\n",
    "nnp = np.random.normal(loc=0.0, scale=stddev, size=shape_nnp).astype(rtype)\n",
    "stp = np.random.normal(loc=0.0, scale=stddev, size=shape_stp).astype(rtype)\n",
    "#Operator Pool\n",
    "unbound_opeartor_pool = [generate_pauli_string(n=8,seed=i)[0] for i in range(8)]\n",
    "bound_opeartor_pool = [generate_pauli_string(n=8,seed=i)[1] for i in range(8,12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = ops.Softmax(axis=-1)\n",
    "\n",
    "out = softmax(Tensor(stp, ms.float32))\n",
    "out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TimeEvolution(QubitOperator(terms=unbound_opeartor_pool[0],coefficient=-0.213),-0.25).circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DQAS_ansatz(Structure_p:np.array,Ansatz_p:np.array,n_layer:int,n_qbits:int=8):\n",
    "    \"\"\"\n",
    "    和 DQAS 文章描述的一致，生成权重线路\n",
    "    \"\"\"\n",
    "    stp = softmax(Tensor(Structure_p, ms.float32))\n",
    "    ansatz = Circuit()\n",
    "    for i in range(n_layer):\n",
    "        \n",
    "        paramertized_part_count=0\n",
    "        for index_op,each_op in enumerate(unbound_opeartor_pool):\n",
    "\n",
    "            ansatz_param = Ansatz_p[i,index_op]\n",
    "            Structure_param =float(stp[i,index_op])\n",
    "            ansatz += TimeEvolution(QubitOperator(terms=each_op,coefficient=ansatz_param),time=Structure_param).circuit\n",
    "            paramertized_part_count+=1\n",
    "            \n",
    "        for index_op,each_op in enumerate(bound_opeartor_pool):\n",
    "            #print(index_op,each_op)\n",
    "            op = GroupedPauli('IZZYYXZI')\n",
    "            tmp_cir = Circuit([GroupedPauli('IZZYYXZI').on(range(n_qbits))])\n",
    "            matrix = tmp_cir.matrix()\n",
    "            print(matrix.shape)\n",
    "            ansatz += UnivMathGate(matrix_value=matrix*stp[i,index_op+paramertized_part_count],name=op.pauli_string).on(range(n_qbits))  \n",
    "    \n",
    "    \n",
    "    #以下开始计算 loss\n",
    "    # Encoder\n",
    "    prg = PRGenerator('alpha')\n",
    "    nqbits = n_qbits\n",
    "    encoder = Circuit()\n",
    "    encoder += UN(H, nqbits)                                  # H门作用在每1位量子比特\n",
    "    for i in range(nqbits):                                   # i = 0, 1, 2, 3\n",
    "        encoder += RY(prg.new()).on(i)                 # RZ(alpha_i)门作用在第i位量子比特\n",
    "    encoder = encoder.no_grad()\n",
    "    encoder = encoder.as_encoder()# Encoder作为整个量子神经网络的第一层，不用对编码线路中的梯度求导数，因此加入no_grad()\n",
    "    \n",
    "    hams = [Hamiltonian(QubitOperator(f'Z{i}')) for i in [0,1]]\n",
    "    #ansatz = ansatz.as_ansatz()\n",
    "    ms.set_context(mode=ms.PYNATIVE_MODE, device_target=\"CPU\")\n",
    "    circuit = encoder+ ansatz.as_ansatz()    \n",
    "    sim = Simulator('mqvector', n_qubits=nqbits)\n",
    "    grad_ops = sim.get_expectation_with_grad(hams,\n",
    "                                         circuit,\n",
    "                                         parallel_worker=5)\n",
    "    \n",
    "    QuantumNet = MQLayer(circuit, hams, sim, grad_ops)\n",
    "    loss_fn = SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')    \n",
    "    sum_loss = 0.0\n",
    "    #统计所有数据的平均损失\n",
    "    all_data = Tensor(X_train,ms.float32)\n",
    "    all_label = Tensor(y_train,ms.int8)\n",
    "    loss_value = loss_fn()\n",
    "    \n",
    "    \n",
    "    \n",
    "      \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ansatz = DQAS_ansatz(circuit=Circuit(),Structure_p=stp,Ansatz_p=nnp,n_layer=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = GroupedPauli(pauli_string='IZZYYXZI')\n",
    "circ1 = Circuit([GroupedPauli('IZZYYXZI').on(range(8))])\n",
    "matrix = circ1.matrix()\n",
    "matrix.shape\n",
    "# UnivMathGate(matrix_value=matrix*0.12,name=op.pauli_string).n_qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit = Circuit()\n",
    "circuit += RX(0.0).on(0)\n",
    "circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = Simulator(backend='mqvector', n_qubits=1)\n",
    "sim.reset()\n",
    "sim.apply_circuit(circuit=circuit)\n",
    "sim.get_qs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore as ms\n",
    "from mindspore import Tensor, ops, nn\n",
    "from mindspore.ops import composite as C\n",
    "import numpy as np\n",
    "\n",
    "# 定义一个简单的函数\n",
    "def f(x, y):\n",
    "    return x**2 + 2*y\n",
    "\n",
    "# 包装函数以便计算值和梯度\n",
    "def value_and_grad(f, argnums=(0,)):\n",
    "    def wrapper(*args):\n",
    "        # 将输入转换为 MindSpore 的 Tensor\n",
    "        ms_args = [Tensor(arg, dtype=ms.float32) for arg in args]\n",
    "        \n",
    "        # 定义计算梯度的函数\n",
    "        def grad_fn(*ms_args):\n",
    "            return f(*ms_args)\n",
    "        \n",
    "        # 计算函数值\n",
    "        value = f(*ms_args)\n",
    "        \n",
    "        # 计算梯度\n",
    "        grads = C.GradOperation(get_all=True, sens_param=False)(grad_fn)(*ms_args)\n",
    "        \n",
    "        # 提取指定参数的梯度\n",
    "        selected_grads = [grads[i] for i in argnums]\n",
    "        \n",
    "        return value.asnumpy(), [g.asnumpy() for g in selected_grads]\n",
    "    \n",
    "    return wrapper\n",
    "\n",
    "# 示例使用\n",
    "g = value_and_grad(f)\n",
    "value, grad = g(np.array(1.0), np.array(2.0))\n",
    "print(\"Value:\", value)  # 输出: 5.0\n",
    "print(\"Grad:\", grad)    # 输出: [2.0]\n",
    "\n",
    "g = value_and_grad(f, argnums=(0, 1))\n",
    "value, grads = g(np.array(1.0), np.array(2.0))\n",
    "print(\"Value:\", value)  # 输出: 5.0\n",
    "print(\"Grads:\", grads)  # 输出: [2.0, 2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore as ms\n",
    "from mindspore import Tensor\n",
    "from mindspore.nn import SoftmaxCrossEntropyWithLogits\n",
    "import numpy as np\n",
    "\n",
    "# 定义损失函数\n",
    "loss_fn = SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "\n",
    "# 示例输入数据和标签\n",
    "logits = Tensor(np.array([[1.0, 2.0], [1.0, 2.0]]), ms.float32)\n",
    "labels = Tensor(np.array([2, 1]), ms.int32)\n",
    "\n",
    "# 计算损失值\n",
    "loss_value = loss_fn(logits, labels)\n",
    "\n",
    "# 打印损失值\n",
    "print(\"Loss value:\", loss_value.asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
