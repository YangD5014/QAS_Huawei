{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/MindSpore/lib/python3.9/site-packages/mindquantum/simulator/__init__.py:17: UserWarning: Unable import mqvector gpu backend due to: cannot import name '_mq_vector_gpu' from partially initialized module 'mindquantum' (most likely due to a circular import) (/opt/miniconda3/envs/MindSpore/lib/python3.9/site-packages/mindquantum/__init__.py)\n",
      "  from .available_simulator import SUPPORTED_SIMULATOR\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mindquantum.core.gates import RX, RY, RZ, H, X, Y, Z, CNOT\n",
    "from mindquantum.core.circuit import Circuit,UN\n",
    "import mindspore as ms\n",
    "from mindquantum.simulator import  Simulator\n",
    "from mindquantum.core.gates import GroupedPauli\n",
    "from mindquantum.core.operators import TimeEvolution,QubitOperator\n",
    "from mindquantum.core.parameterresolver import PRGenerator\n",
    "from mindquantum.core.circuit import change_param_name\n",
    "from mindspore.nn import Adam  \n",
    "import random\n",
    "from mindspore import Tensor,ops,Parameter\n",
    "from mindquantum.core.gates import UnivMathGate\n",
    "from mindquantum.core.operators import Hamiltonian             # 导入Hamiltonian模块，用于构建哈密顿量\n",
    "from mindquantum.framework import MQLayer,MQOps\n",
    "from torchvision import datasets\n",
    "import mindspore.numpy as mnp\n",
    "import sys\n",
    "from typing import Union\n",
    "sys.path.append('..')\n",
    "from Test_tool import Test_ansatz\n",
    "from data_processing import X_train,X_test,y_train,y_test\n",
    "from mindspore.train import Accuracy, Model, LossMonitor  \n",
    "from mindspore.dataset import NumpySlicesDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pauli_ops=\\\n",
    "['X0 X1','X1 X2','X3 X4','X4 X5','X6 X7','X7 X0',\n",
    " 'Y0 Y1','Y1 Y2','Y3 Y4','Y4 Y5','Y6 Y7','Y7 Y0',\n",
    " 'Z0 Z1','Z1 Z2','Z3 Z4','Z4 Z5','Z6 Z7','Z7 Z0',\\\n",
    " 'X0 Y1 Z2 X3','Y1 Z2 X3 X4']\n",
    "\n",
    "unparameterized_circuit = \\\n",
    "[UN(Z, maps_obj = [0,1,2,3], maps_ctrl = [4,5,6,7]),\n",
    " UN(Z, maps_obj = [4,5,6,7], maps_ctrl = [0,1,2,3]),\n",
    " UN(X, maps_obj = [0,1,2,3], maps_ctrl = [4,5,6,7]),\n",
    " UN(X, maps_obj = [4,5,6,7], maps_ctrl = [0,1,2,3]),\n",
    " UN(Y, maps_obj = [0,1,2,3], maps_ctrl = [4,5,6,7]),\n",
    " UN(Y, maps_obj = [4,5,6,7], maps_ctrl = [0,1,2,3]),\n",
    " ]\n",
    "ansatz_pr = PRGenerator('ansatz')\n",
    "parameterized_circuit=[TimeEvolution(QubitOperator(i,ansatz_pr.new()),time=0.5).circuit for i in Pauli_ops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_parametized = len(parameterized_circuit)\n",
    "shape_unparameterized = len(unparameterized_circuit)\n",
    "num_layer=12\n",
    "shape_nnp = (num_layer,shape_parametized)\n",
    "shape_stp = (num_layer,shape_unparameterized+shape_parametized)\n",
    "stddev = 0.03\n",
    "nnp = np.random.normal(loc=0.0, scale=stddev, size=shape_nnp)\n",
    "stp = np.random.normal(loc=0.0, scale=stddev, size=shape_stp)\n",
    "ops_onehot = ops.OneHot(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DQAS_tool import best_from_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[12, 26], dtype=Int32, value=\n",
       "[[0, 0, 0 ... 0, 0, 0],\n",
       " [0, 0, 0 ... 0, 0, 0],\n",
       " [0, 0, 0 ... 1, 0, 0],\n",
       " ...\n",
       " [0, 0, 0 ... 0, 0, 0],\n",
       " [0, 0, 0 ... 0, 0, 0],\n",
       " [0, 0, 0 ... 0, 0, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "can = best_from_structure(structures=stp)\n",
    "standard_stp = ops_onehot(best_from_structure(structures=stp),\n",
    "                          shape_unparameterized+shape_parametized,\n",
    "                          ms.Tensor(1,ms.int32),ms.Tensor(0,ms.int32))\n",
    "\n",
    "standard_stp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[12], dtype=Int32, value= [11, 20, 23, 19,  3, 15, 14, 19,  3, 11, 22,  4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mindspore_ansatz3(Structure_p:np.array,\n",
    "                     parameterized_pool:list[Circuit],\n",
    "                     unparameterized_pool:list[Circuit],\n",
    "                     num_layer:int=6,\n",
    "                     n_qbits:int=8):\n",
    "    \"\"\"\n",
    "    和 DQAS 文章描述的一致，生成权重线路\n",
    "    更新了非参数化门的算符池引入\n",
    "    Structure_p:np.array DQAS中的权重参数,\n",
    "    Ansatz_p:np.array  DQAS中的Ansatz参数,\n",
    "    \n",
    "    \"\"\"\n",
    "    if Structure_p.shape[0] != num_layer:\n",
    "        raise ValueError('Structure_p shape must be equal to num_layer')\n",
    "    \n",
    "    if Structure_p.shape[1] != len(parameterized_pool)+len(unparameterized_pool):\n",
    "        raise ValueError('Structure_p shape must be equal to size of pool')\n",
    "    # softmax = ops.Softmax()\n",
    "    # my_stp = softmax(Tensor(Structure_p, ms.float32))\n",
    "    if isinstance(Structure_p, np.ndarray):\n",
    "        my_stp = ms.Tensor(Structure_p, ms.float32)\n",
    "    else:\n",
    "        my_stp = Structure_p\n",
    "        \n",
    "    prg = PRGenerator('encoder')\n",
    "    nqbits = n_qbits\n",
    "    encoder = Circuit()\n",
    "    # encoder += UN(H, nqbits)                                 \n",
    "    for i in range(nqbits):                                  \n",
    "        encoder += RY(prg.new()).on(i)    \n",
    "    encoder = encoder.as_encoder()             \n",
    "        \n",
    "    ansatz = Circuit()\n",
    "    pr_gen = PRGenerator('ansatz')\n",
    "    #print(my_stp.shape)\n",
    "    for layer_index in range(my_stp.shape[0]):\n",
    "        for op_index in range(my_stp.shape[1]):\n",
    "            if my_stp[layer_index,op_index] == 0:\n",
    "                continue\n",
    "            if op_index < len(parameterized_pool):\n",
    "                before_ansatz = parameterized_pool[op_index]\n",
    "                before_ansatz = change_param_name(circuit_fn=before_ansatz,name_map={before_ansatz.ansatz_params_name[0]:f'ansatz{layer_index}'})\n",
    "                ansatz += before_ansatz\n",
    "            else:\n",
    "                ansatz += unparameterized_pool[op_index-len(parameterized_pool)]\n",
    "    \n",
    "    \n",
    "    \n",
    "    finnal_ansatz = encoder.as_encoder() + ansatz.as_ansatz()\n",
    "    # print(finnal_ansatz)\n",
    "    # name_map = dict(zip(finnal_ansatz.ansatz_params_name,[f'ansatz{i}'for i in range(len(finnal_ansatz.ansatz_params_name))]))\n",
    "    # finnal_ansatz = change_param_name(circuit_fn=finnal_ansatz,name_map=name_map)\n",
    "    return finnal_ansatz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ansatz = Mindspore_ansatz3(Structure_p=standard_stp,parameterized_pool=parameterized_circuit,unparameterized_pool=unparameterized_circuit,num_layer=12,n_qbits=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ansatz0',\n",
       " 'ansatz3',\n",
       " 'ansatz4',\n",
       " 'ansatz5',\n",
       " 'ansatz6',\n",
       " 'ansatz7',\n",
       " 'ansatz8',\n",
       " 'ansatz9',\n",
       " 'ansatz11']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ansatz.ansatz_params_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['encoder0',\n",
       " 'encoder1',\n",
       " 'encoder2',\n",
       " 'encoder3',\n",
       " 'encoder4',\n",
       " 'encoder5',\n",
       " 'encoder6',\n",
       " 'encoder7']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ansatz.encoder_params_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 20, loss is 0.7484782338142395\n",
      "epoch: 1 step: 40, loss is 0.7556942701339722\n",
      "epoch: 2 step: 11, loss is 0.6591635942459106\n",
      "epoch: 2 step: 31, loss is 0.6708909273147583\n",
      "epoch: 3 step: 2, loss is 0.6348642110824585\n",
      "epoch: 3 step: 22, loss is 0.669664740562439\n",
      "epoch: 3 step: 42, loss is 0.7045347690582275\n",
      "epoch: 4 step: 13, loss is 0.6332474946975708\n",
      "epoch: 4 step: 33, loss is 0.7044292688369751\n",
      "epoch: 5 step: 4, loss is 0.5578922033309937\n",
      "epoch: 5 step: 24, loss is 0.682957112789154\n",
      "epoch: 5 step: 44, loss is 0.6039729118347168\n",
      "epoch: 6 step: 15, loss is 0.7316300272941589\n",
      "epoch: 6 step: 35, loss is 0.6445085406303406\n",
      "epoch: 7 step: 6, loss is 0.6514734029769897\n",
      "epoch: 7 step: 26, loss is 0.6697326302528381\n",
      "epoch: 7 step: 46, loss is 0.6712834239006042\n",
      "epoch: 8 step: 17, loss is 0.5959731936454773\n",
      "epoch: 8 step: 37, loss is 0.5690423250198364\n",
      "epoch: 9 step: 8, loss is 0.7655727863311768\n",
      "epoch: 9 step: 28, loss is 0.6961480975151062\n",
      "epoch: 9 step: 48, loss is 0.603275716304779\n",
      "epoch: 10 step: 19, loss is 0.5714854001998901\n",
      "epoch: 10 step: 39, loss is 0.5598112344741821\n",
      "epoch: 11 step: 10, loss is 0.6270891427993774\n",
      "epoch: 11 step: 30, loss is 0.6045563220977783\n",
      "epoch: 12 step: 1, loss is 0.6564871072769165\n",
      "epoch: 12 step: 21, loss is 0.5666705369949341\n",
      "epoch: 12 step: 41, loss is 0.6380983591079712\n",
      "epoch: 13 step: 12, loss is 0.5326664447784424\n",
      "epoch: 13 step: 32, loss is 0.48294100165367126\n",
      "epoch: 14 step: 3, loss is 0.6256760954856873\n",
      "epoch: 14 step: 23, loss is 0.5478101372718811\n",
      "epoch: 14 step: 43, loss is 0.6902475357055664\n",
      "epoch: 15 step: 14, loss is 0.7563208341598511\n",
      "epoch: 15 step: 34, loss is 0.6348069310188293\n",
      "epoch: 16 step: 5, loss is 0.6423059701919556\n",
      "epoch: 16 step: 25, loss is 0.6586616635322571\n",
      "epoch: 16 step: 45, loss is 0.6439807415008545\n",
      "epoch: 17 step: 16, loss is 0.6020910143852234\n",
      "epoch: 17 step: 36, loss is 0.6328541040420532\n",
      "epoch: 18 step: 7, loss is 0.6519177556037903\n",
      "epoch: 18 step: 27, loss is 0.5519083142280579\n",
      "epoch: 18 step: 47, loss is 0.6728478670120239\n",
      "epoch: 19 step: 18, loss is 0.6381523013114929\n",
      "epoch: 19 step: 38, loss is 0.7298966646194458\n",
      "epoch: 20 step: 9, loss is 0.531332790851593\n",
      "epoch: 20 step: 29, loss is 0.6736336946487427\n",
      "epoch: 20 step: 49, loss is 0.5675823092460632\n"
     ]
    }
   ],
   "source": [
    "acc = Test_ansatz(ansatz=ansatz,learning_rate=0.3,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
