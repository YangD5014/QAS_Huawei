{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please first ``pip install -U qiskit`` to enable related functionality in translation module\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorcircuit as tc\n",
    "import tensorflow as tf\n",
    "K = tc.set_backend(\"tensorflow\")\n",
    "ctype, rtype = tc.set_dtype(\"complex128\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rx0(theta):\n",
    "    return K.kron(\n",
    "        K.cos(theta) * K.eye(2) + 1.0j * K.sin(theta) * tc.gates._x_matrix, K.eye(2)\n",
    "    )\n",
    "\n",
    "\n",
    "def rx1(theta):\n",
    "    return K.kron(\n",
    "        K.eye(2), K.cos(theta) * K.eye(2) + 1.0j * K.sin(theta) * tc.gates._x_matrix\n",
    "    )\n",
    "\n",
    "\n",
    "def ry0(theta):\n",
    "    return K.kron(\n",
    "        K.cos(theta) * K.eye(2) + 1.0j * K.sin(theta) * tc.gates._y_matrix, K.eye(2)\n",
    "    )\n",
    "\n",
    "\n",
    "def ry1(theta):\n",
    "    return K.kron(\n",
    "        K.eye(2), K.cos(theta) * K.eye(2) + 1.0j * K.sin(theta) * tc.gates._y_matrix\n",
    "    )\n",
    "\n",
    "\n",
    "def rz0(theta):\n",
    "    return K.kron(\n",
    "        K.cos(theta) * K.eye(2) + 1.0j * K.sin(theta) * tc.gates._z_matrix, K.eye(2)\n",
    "    )\n",
    "\n",
    "\n",
    "def rz1(theta):\n",
    "    return K.kron(\n",
    "        K.eye(2), K.cos(theta) * K.eye(2) + 1.0j * K.sin(theta) * tc.gates._z_matrix\n",
    "    )\n",
    "\n",
    "\n",
    "def cnot01():\n",
    "    return K.cast(K.convert_to_tensor(tc.gates._cnot_matrix), ctype)\n",
    "\n",
    "\n",
    "def cnot10():\n",
    "    return K.cast(\n",
    "        K.convert_to_tensor(\n",
    "            np.array([[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
    "        ),\n",
    "        ctype,\n",
    "    )\n",
    "\n",
    "\n",
    "ops_repr = [\"rx0\", \"rx1\", \"ry0\", \"ry1\", \"rz0\", \"rz1\", \"cnot01\", \"cnot10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, p, ch = 2, 3, 8\n",
    "# 量子比特数、层数、操作池大小\n",
    "\n",
    "target = tc.array_to_tensor(np.array([1, 0, 0, 1.0]) / np.sqrt(2.0))\n",
    "# 目标波函数，我们这里使用 GHZ2 状态作为目标函数\n",
    "\n",
    "\n",
    "def ansatz(params, structures):\n",
    "    c = tc.Circuit(n)\n",
    "    params = K.cast(params, ctype)\n",
    "    structures = K.cast(structures, ctype)\n",
    "    for i in range(p):\n",
    "        c.any(\n",
    "            0,\n",
    "            1,\n",
    "            unitary=structures[i, 0] * rx0(params[i, 0])\n",
    "            + structures[i, 1] * rx1(params[i, 1])\n",
    "            + structures[i, 2] * ry0(params[i, 2])\n",
    "            + structures[i, 3] * ry1(params[i, 3])\n",
    "            + structures[i, 4] * rz0(params[i, 4])\n",
    "            + structures[i, 5] * rz1(params[i, 5])\n",
    "            + structures[i, 6] * cnot01()\n",
    "            + structures[i, 7] * cnot10(),\n",
    "        )\n",
    "    s = c.state()\n",
    "    loss = K.sum(K.abs(target - s))\n",
    "    return loss\n",
    "\n",
    "\n",
    "vag1 = K.jit(K.vvag(ansatz, argnums=0, vectorized_argnums=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_from_structure(structures, batch=1):\n",
    "    prob = K.softmax(K.real(structures), axis=-1)\n",
    "    return np.array([np.random.choice(ch, p=K.numpy(prob[i])) for i in range(p)])\n",
    "\n",
    "\n",
    "@K.jit\n",
    "def best_from_structure(structures):\n",
    "    return K.argmax(structures, axis=-1)\n",
    "\n",
    "\n",
    "@K.jit\n",
    "def nmf_gradient(structures, oh):\n",
    "    \"\"\"\n",
    "    根据朴素平均场概率模型计算蒙特卡洛梯度\n",
    "    \"\"\"\n",
    "    choice = K.argmax(oh, axis=-1)\n",
    "    prob = K.softmax(K.real(structures), axis=-1)\n",
    "    indices = K.transpose(K.stack([K.cast(tf.range(p), \"int64\"), choice]))\n",
    "    prob = tf.gather_nd(prob, indices)\n",
    "    prob = K.reshape(prob, [-1, 1])\n",
    "    prob = K.tile(prob, [1, ch])\n",
    "\n",
    "    return tf.tensor_scatter_nd_add(\n",
    "        tf.cast(-prob, dtype=ctype),\n",
    "        indices,\n",
    "        tf.ones([p], dtype=ctype),\n",
    "    )\n",
    "\n",
    "\n",
    "nmf_gradient_vmap = K.vmap(nmf_gradient, vectorized_argnums=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnp = K.implicit_randn(stddev=0.02, shape=[p, 6], dtype=rtype)\n",
    "stp = K.implicit_randn(stddev=0.02, shape=[p, 8], dtype=rtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([7, 3, 8])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_stuctures = K.onehot(\n",
    "    np.stack([sampling_from_structure(stp) for _ in range(7)]), num=8\n",
    ")\n",
    "batched_stuctures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x350f5d820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([7, 3, 8])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = nmf_gradient_vmap(stp, batched_stuctures)  # \\nabla lnp\n",
    "gs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "infd, gnnp = vag1(nnp, batched_stuctures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "gstp = [K.cast((infd[i] - 0), ctype) * gs[i] for i in range(infd.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infd.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gstp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 8), dtype=complex128, numpy=\n",
       "array([[-0.13027031+0.j, -0.13027031+0.j,  0.86972969+0.j,\n",
       "        -0.13027031+0.j, -0.13027031+0.j, -0.13027031+0.j,\n",
       "        -0.13027031+0.j, -0.13027031+0.j],\n",
       "       [-0.12723928+0.j, -0.12723928+0.j, -0.12723928+0.j,\n",
       "        -0.12723928+0.j, -0.12723928+0.j, -0.12723928+0.j,\n",
       "         0.87276072+0.j, -0.12723928+0.j],\n",
       "       [ 0.87729931+0.j, -0.12270069+0.j, -0.12270069+0.j,\n",
       "        -0.12270069+0.j, -0.12270069+0.j, -0.12270069+0.j,\n",
       "        -0.12270069+0.j, -0.12270069+0.j]])>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_gradient(stp,batched_stuctures[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False\n",
    "epochs = 400\n",
    "batch = 256\n",
    "lr = tf.keras.optimizers.schedules.ExponentialDecay(0.06, 100, 0.5)\n",
    "structure_opt = tc.backend.optimizer(tf.keras.optimizers.Adam(0.12))\n",
    "network_opt = tc.backend.optimizer(tf.keras.optimizers.Adam(lr))\n",
    "nnp = K.implicit_randn(stddev=0.02, shape=[p, 6], dtype=rtype)\n",
    "stp = K.implicit_randn(stddev=0.02, shape=[p, 8], dtype=rtype)\n",
    "avcost1 = 0\n",
    "for epoch in range(epochs):  # 更新结构参数的迭代\n",
    "    avcost2 = avcost1\n",
    "    costl = []\n",
    "    batched_stuctures = K.onehot(\n",
    "        np.stack([sampling_from_structure(stp) for _ in range(batch)]), num=8\n",
    "    )\n",
    "    infd, gnnp = vag1(nnp, batched_stuctures)\n",
    "    gs = nmf_gradient_vmap(stp, batched_stuctures)  # \\nabla lnp\n",
    "    gstp = [K.cast((infd[i] - avcost2), ctype) * gs[i] for i in range(infd.shape[0])]\n",
    "    gstp = K.real(K.sum(gstp, axis=0) / infd.shape[0])\n",
    "    avcost1 = K.sum(infd) / infd.shape[0]\n",
    "    nnp = network_opt.update(gnnp, nnp)\n",
    "    stp = structure_opt.update(gstp, stp)\n",
    "\n",
    "    if epoch % 40 == 0 or epoch == epochs - 1:\n",
    "        print(\"----------epoch %s-----------\" % epoch)\n",
    "        print(\n",
    "            \"batched average loss: \",\n",
    "            np.mean(avcost1),\n",
    "        )\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                \"strcuture parameter: \\n\",\n",
    "                stp.numpy(),\n",
    "                \"\\n network parameter: \\n\",\n",
    "                nnp.numpy(),\n",
    "            )\n",
    "\n",
    "        cand_preset = best_from_structure(stp)\n",
    "        print(\"best candidates so far:\", [ops_repr[i] for i in cand_preset])\n",
    "        print(\n",
    "            \"corresponding weights for each gate:\",\n",
    "            [K.numpy(nnp[j, i]) if i < 6 else 0.0 for j, i in enumerate(cand_preset)],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ansatz2(params, structures):\n",
    "    c = tc.Circuit(n)\n",
    "    params = K.cast(params, ctype)\n",
    "    structures = K.softmax(structures, axis=-1)\n",
    "    structures = K.cast(structures, ctype)\n",
    "    for i in range(p):\n",
    "        c.any(\n",
    "            0,\n",
    "            1,\n",
    "            unitary=structures[i, 0] * rx0(params[i, 0])\n",
    "            + structures[i, 1] * rx1(params[i, 1])\n",
    "            + structures[i, 2] * ry0(params[i, 2])\n",
    "            + structures[i, 3] * ry1(params[i, 3])\n",
    "            + structures[i, 4] * rz0(params[i, 4])\n",
    "            + structures[i, 5] * rz1(params[i, 5])\n",
    "            + structures[i, 6] * cnot01()\n",
    "            + structures[i, 7] * cnot10(),\n",
    "        )\n",
    "    s = c.state()\n",
    "    s /= K.norm(s)\n",
    "    loss = K.sum(K.abs(target - s))\n",
    "    return loss\n",
    "\n",
    "\n",
    "vag2 = K.jit(K.value_and_grad(ansatz2, argnums=(0, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True\n",
    "epochs = 700\n",
    "lr = tf.keras.optimizers.schedules.ExponentialDecay(0.05, 200, 0.5)\n",
    "structure_opt = tc.backend.optimizer(tf.keras.optimizers.Adam(0.04))\n",
    "network_opt = tc.backend.optimizer(tf.keras.optimizers.Adam(lr))\n",
    "nnp = K.implicit_randn(stddev=0.02, shape=[p, 6], dtype=rtype)\n",
    "stp = K.implicit_randn(stddev=0.02, shape=[p, 8], dtype=rtype)\n",
    "for epoch in range(epochs):\n",
    "    infd, (gnnp, gstp) = vag2(nnp, stp)\n",
    "\n",
    "    nnp = network_opt.update(gnnp, nnp)\n",
    "    stp = structure_opt.update(gstp, stp)\n",
    "    if epoch % 70 == 0 or epoch == epochs - 1:\n",
    "        print(\"----------epoch %s-----------\" % epoch)\n",
    "        print(\n",
    "            \"batched average loss: \",\n",
    "            np.mean(infd),\n",
    "        )\n",
    "        if verbose:\n",
    "            print(\n",
    "                \"strcuture parameter: \\n\",\n",
    "                stp.numpy(),\n",
    "                \"\\n network parameter: \\n\",\n",
    "                nnp.numpy(),\n",
    "            )\n",
    "\n",
    "        cand_preset = best_from_structure(stp)\n",
    "        print(\"best candidates so far:\", [ops_repr[i] for i in cand_preset])\n",
    "        print(\n",
    "            \"corresponding weights for each gate:\",\n",
    "            [K.numpy(nnp[j, i]) if i < 6 else 0.0 for j, i in enumerate(cand_preset)],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_structure = K.onehot(np.array([2, 4, 6]), num=8)\n",
    "chosen_structure = K.reshape(chosen_structure, [1, p, ch])\n",
    "chosen_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_opt = tc.backend.optimizer(tf.keras.optimizers.Adam(1e-3))\n",
    "nnp = K.implicit_randn(stddev=0.02, shape=[p, 6], dtype=rtype)\n",
    "verbose = True\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    infd, gnnp = vag1(nnp, chosen_structure)\n",
    "    nnp = network_opt.update(gnnp, nnp)\n",
    "    if epoch % 60 == 0 or epoch == epochs - 1:\n",
    "        print(epoch, \"loss: \", K.numpy(infd[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
