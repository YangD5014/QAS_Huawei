{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please first ``pip install -U qiskit`` to enable related functionality in translation module\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorcircuit as tc\n",
    "import tensorflow as tf\n",
    "K = tc.set_backend(\"tensorflow\")\n",
    "ctype, rtype = tc.set_dtype(\"complex128\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'complex128'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'float64'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rx0(theta):\n",
    "    return K.kron(\n",
    "        K.cos(theta) * K.eye(2) + 1.0j * K.sin(theta) * tc.gates._x_matrix, K.eye(2)\n",
    "    )\n",
    "\n",
    "\n",
    "def rx1(theta):\n",
    "    return K.kron(\n",
    "        K.eye(2), K.cos(theta) * K.eye(2) + 1.0j * K.sin(theta) * tc.gates._x_matrix\n",
    "    )\n",
    "\n",
    "\n",
    "def ry0(theta):\n",
    "    return K.kron(\n",
    "        K.cos(theta) * K.eye(2) + 1.0j * K.sin(theta) * tc.gates._y_matrix, K.eye(2)\n",
    "    )\n",
    "\n",
    "\n",
    "def ry1(theta):\n",
    "    return K.kron(\n",
    "        K.eye(2), K.cos(theta) * K.eye(2) + 1.0j * K.sin(theta) * tc.gates._y_matrix\n",
    "    )\n",
    "\n",
    "\n",
    "def rz0(theta):\n",
    "    return K.kron(\n",
    "        K.cos(theta) * K.eye(2) + 1.0j * K.sin(theta) * tc.gates._z_matrix, K.eye(2)\n",
    "    )\n",
    "\n",
    "\n",
    "def rz1(theta):\n",
    "    return K.kron(\n",
    "        K.eye(2), K.cos(theta) * K.eye(2) + 1.0j * K.sin(theta) * tc.gates._z_matrix\n",
    "    )\n",
    "\n",
    "\n",
    "def cnot01():\n",
    "    return K.cast(K.convert_to_tensor(tc.gates._cnot_matrix), ctype)\n",
    "\n",
    "\n",
    "def cnot10():\n",
    "    return K.cast(\n",
    "        K.convert_to_tensor(\n",
    "            np.array([[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
    "        ),\n",
    "        ctype,\n",
    "    )\n",
    "\n",
    "\n",
    "ops_repr = [\"rx0\", \"rx1\", \"ry0\", \"ry1\", \"rz0\", \"rz1\", \"cnot01\", \"cnot10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, p, ch = 2, 3, 8\n",
    "# 量子比特数、层数、操作池大小\n",
    "\n",
    "target = tc.array_to_tensor(np.array([1, 0, 0, 1.0]) / np.sqrt(2.0))\n",
    "# 目标波函数，我们这里使用 GHZ2 状态作为目标函数\n",
    "\n",
    "\n",
    "def ansatz(params, structures):\n",
    "    c = tc.Circuit(n)\n",
    "    params = K.cast(params, ctype)\n",
    "    structures = K.cast(structures, ctype)\n",
    "    for i in range(p):\n",
    "        c.any(\n",
    "            0,\n",
    "            1,\n",
    "            unitary=structures[i, 0] * rx0(params[i, 0])\n",
    "            + structures[i, 1] * rx1(params[i, 1])\n",
    "            + structures[i, 2] * ry0(params[i, 2])\n",
    "            + structures[i, 3] * ry1(params[i, 3])\n",
    "            + structures[i, 4] * rz0(params[i, 4])\n",
    "            + structures[i, 5] * rz1(params[i, 5])\n",
    "            + structures[i, 6] * cnot01()\n",
    "            + structures[i, 7] * cnot10(),\n",
    "        )\n",
    "    s = c.state()\n",
    "    loss = K.sum(K.abs(target - s))\n",
    "    return loss\n",
    "\n",
    "\n",
    "vag1 = K.jit(K.vvag(ansatz, argnums=0, vectorized_argnums=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_from_structure(structures, batch=1):\n",
    "    prob = K.softmax(K.real(structures), axis=-1)\n",
    "    return np.array([np.random.choice(ch, p=K.numpy(prob[i])) for i in range(p)])\n",
    "\n",
    "\n",
    "@K.jit\n",
    "def best_from_structure(structures):\n",
    "    return K.argmax(structures, axis=-1)\n",
    "\n",
    "\n",
    "@K.jit\n",
    "def nmf_gradient(structures, oh):\n",
    "    \"\"\"\n",
    "    根据朴素平均场概率模型计算蒙特卡洛梯度\n",
    "    \"\"\"\n",
    "    choice = K.argmax(oh, axis=-1)\n",
    "    prob = K.softmax(K.real(structures), axis=-1)\n",
    "    indices = K.transpose(K.stack([K.cast(tf.range(p), \"int64\"), choice]))\n",
    "    prob = tf.gather_nd(prob, indices)\n",
    "    prob = K.reshape(prob, [-1, 1])\n",
    "    prob = K.tile(prob, [1, ch])\n",
    "\n",
    "    return tf.tensor_scatter_nd_add(\n",
    "        tf.cast(-prob, dtype=ctype),\n",
    "        indices,\n",
    "        tf.ones([p], dtype=ctype),\n",
    "    )\n",
    "\n",
    "\n",
    "nmf_gradient_vmap = K.vmap(nmf_gradient, vectorized_argnums=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnp = K.implicit_randn(stddev=0.02, shape=[p, 6], dtype=rtype)\n",
    "stp = K.implicit_randn(stddev=0.02, shape=[p, 8], dtype=rtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 8), dtype=float64, numpy=\n",
       "array([[ 0.03549599,  0.00259103,  0.02050921,  0.04924461, -0.00708516,\n",
       "         0.03031192,  0.00734741,  0.00289678],\n",
       "       [-0.01013225, -0.00139695,  0.01322092,  0.00611694,  0.01441615,\n",
       "         0.01181014,  0.01603067,  0.01049271],\n",
       "       [-0.00903826, -0.025523  , -0.0189485 ,  0.02152791,  0.00156384,\n",
       "         0.01501239, -0.00063014,  0.03422753]])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------epoch 0-----------\n",
      "batched average loss:  1.4350284930905612\n",
      "best candidates so far: ['ry1', 'rz0', 'rx0']\n",
      "corresponding weights for each gate: [0.03687752986503738, -0.047695993774942755, 0.04552400264153701]\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x334951c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x334951310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "----------epoch 40-----------\n",
      "batched average loss:  1.013661786785497\n",
      "best candidates so far: ['rz1', 'rz0', 'rz0']\n",
      "corresponding weights for each gate: [-0.00338954721777787, 0.003513532294152719, 0.0031886893969231165]\n",
      "----------epoch 80-----------\n",
      "batched average loss:  1.0001894815595078\n",
      "best candidates so far: ['rz1', 'rz0', 'rz0']\n",
      "corresponding weights for each gate: [0.00045108170240731665, -0.0013252198169867763, -0.0003939969594297074]\n",
      "----------epoch 120-----------\n",
      "batched average loss:  1.0001383514980922\n",
      "best candidates so far: ['rz1', 'rz0', 'rz0']\n",
      "corresponding weights for each gate: [8.119327330189437e-07, 9.39591774612522e-05, 3.9127445710219864e-05]\n",
      "----------epoch 160-----------\n",
      "batched average loss:  1.000065754484419\n",
      "best candidates so far: ['rz1', 'rz0', 'rz0']\n",
      "corresponding weights for each gate: [5.475451726703511e-06, -1.028169573790192e-05, 2.1555605548884114e-06]\n",
      "----------epoch 200-----------\n",
      "batched average loss:  1.0055685635986382\n",
      "best candidates so far: ['rz1', 'rz0', 'rz0']\n",
      "corresponding weights for each gate: [-5.440575269153459e-07, -9.401783031668913e-07, 8.852087697337414e-07]\n",
      "----------epoch 240-----------\n",
      "batched average loss:  1.0000106038148395\n",
      "best candidates so far: ['rz1', 'rz0', 'rz0']\n",
      "corresponding weights for each gate: [-9.34869180105203e-08, 9.002067371492383e-08, 2.4011249427163287e-08]\n",
      "----------epoch 280-----------\n",
      "batched average loss:  1.0000244231074067\n",
      "best candidates so far: ['rz1', 'rz0', 'rz0']\n",
      "corresponding weights for each gate: [-3.098938707691794e-09, -1.2402587167369958e-08, 5.4470026817758015e-09]\n",
      "----------epoch 320-----------\n",
      "batched average loss:  1.0000083327947193\n",
      "best candidates so far: ['rz1', 'rz0', 'rz0']\n",
      "corresponding weights for each gate: [-2.1610411515877465e-09, -4.105093722428823e-10, 3.451434742491682e-09]\n",
      "----------epoch 360-----------\n",
      "batched average loss:  1.0000028955040303\n",
      "best candidates so far: ['rz1', 'rz0', 'rz0']\n",
      "corresponding weights for each gate: [-3.107517915748671e-10, 1.810345866738477e-10, 4.782033648515068e-11]\n",
      "----------epoch 399-----------\n",
      "batched average loss:  1.0\n",
      "best candidates so far: ['rz1', 'rz0', 'rz0']\n",
      "corresponding weights for each gate: [-2.2531198403222838e-10, 8.017786277336383e-10, -6.972434059030501e-10]\n"
     ]
    }
   ],
   "source": [
    "verbose = False\n",
    "epochs = 400\n",
    "batch = 256\n",
    "lr = tf.keras.optimizers.schedules.ExponentialDecay(0.06, 100, 0.5)\n",
    "structure_opt = tc.backend.optimizer(tf.keras.optimizers.Adam(0.12))\n",
    "network_opt = tc.backend.optimizer(tf.keras.optimizers.Adam(lr))\n",
    "nnp = K.implicit_randn(stddev=0.02, shape=[p, 6], dtype=rtype)\n",
    "stp = K.implicit_randn(stddev=0.02, shape=[p, 8], dtype=rtype)\n",
    "avcost1 = 0\n",
    "for epoch in range(epochs):  # 更新结构参数的迭代\n",
    "    avcost2 = avcost1\n",
    "    costl = []\n",
    "    batched_stuctures = K.onehot(\n",
    "        np.stack([sampling_from_structure(stp) for _ in range(batch)]), num=8\n",
    "    )\n",
    "    infd, gnnp = vag1(nnp, batched_stuctures)\n",
    "    gs = nmf_gradient_vmap(stp, batched_stuctures)  # \\nabla lnp\n",
    "    gstp = [K.cast((infd[i] - avcost2), ctype) * gs[i] for i in range(infd.shape[0])]\n",
    "    gstp = K.real(K.sum(gstp, axis=0) / infd.shape[0])\n",
    "    avcost1 = K.sum(infd) / infd.shape[0]\n",
    "    nnp = network_opt.update(gnnp, nnp)\n",
    "    stp = structure_opt.update(gstp, stp)\n",
    "\n",
    "    if epoch % 40 == 0 or epoch == epochs - 1:\n",
    "        print(\"----------epoch %s-----------\" % epoch)\n",
    "        print(\n",
    "            \"batched average loss: \",\n",
    "            np.mean(avcost1),\n",
    "        )\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                \"strcuture parameter: \\n\",\n",
    "                stp.numpy(),\n",
    "                \"\\n network parameter: \\n\",\n",
    "                nnp.numpy(),\n",
    "            )\n",
    "\n",
    "        cand_preset = best_from_structure(stp)\n",
    "        print(\"best candidates so far:\", [ops_repr[i] for i in cand_preset])\n",
    "        print(\n",
    "            \"corresponding weights for each gate:\",\n",
    "            [K.numpy(nnp[j, i]) if i < 6 else 0.0 for j, i in enumerate(cand_preset)],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ansatz2(params, structures):\n",
    "    c = tc.Circuit(n)\n",
    "    params = K.cast(params, ctype)\n",
    "    structures = K.softmax(structures, axis=-1)\n",
    "    structures = K.cast(structures, ctype)\n",
    "    for i in range(p):\n",
    "        c.any(\n",
    "            0,\n",
    "            1,\n",
    "            unitary=structures[i, 0] * rx0(params[i, 0])\n",
    "            + structures[i, 1] * rx1(params[i, 1])\n",
    "            + structures[i, 2] * ry0(params[i, 2])\n",
    "            + structures[i, 3] * ry1(params[i, 3])\n",
    "            + structures[i, 4] * rz0(params[i, 4])\n",
    "            + structures[i, 5] * rz1(params[i, 5])\n",
    "            + structures[i, 6] * cnot01()\n",
    "            + structures[i, 7] * cnot10(),\n",
    "        )\n",
    "    s = c.state()\n",
    "    s /= K.norm(s)\n",
    "    loss = K.sum(K.abs(target - s))\n",
    "    return loss\n",
    "\n",
    "\n",
    "vag2 = K.jit(K.value_and_grad(ansatz2, argnums=(0, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------epoch 0-----------\n",
      "batched average loss:  1.3028580976115745\n",
      "strcuture parameter: \n",
      " [[ 0.02642551  0.04879337  0.03993834  0.05393528  0.01007346  0.06594783\n",
      "   0.02178556 -0.065861  ]\n",
      " [ 0.03243891  0.05765078  0.04342524  0.03790864  0.03944079  0.01919895\n",
      "   0.06946815 -0.0165585 ]\n",
      " [ 0.01991238  0.02745579  0.05845886  0.04868942  0.09504317  0.07270755\n",
      "   0.04895157 -0.0589975 ]] \n",
      " network parameter: \n",
      " [[-0.04931527  0.01637837 -0.02725512  0.05935174  0.02434643  0.02549461]\n",
      " [-0.03793334  0.04774108 -0.06644895  0.07115726  0.04545609  0.01796591]\n",
      " [-0.03906845  0.05768943 -0.05711509  0.0408206   0.07229365  0.04936205]]\n",
      "best candidates so far: ['rz1', 'cnot01', 'rz0']\n",
      "corresponding weights for each gate: [0.025494614256898068, 0.0, 0.07229365328164147]\n",
      "----------epoch 70-----------\n",
      "batched average loss:  0.6702069440721292\n",
      "strcuture parameter: \n",
      " [[-0.24716255  0.08023233  1.95626993  0.54401311  0.1323524   0.18822557\n",
      "   0.16744054 -0.82487636]\n",
      " [-0.066985    0.3271436   0.80041527  0.3996407   0.37799083  0.3887035\n",
      "   2.41419751 -0.69545938]\n",
      " [-0.62146312 -0.1458026   1.76956069  0.1262549  -0.04086425 -0.05276066\n",
      "   1.9480231  -0.67013741]] \n",
      " network parameter: \n",
      " [[-7.03891215e-03  5.83395376e-03 -1.08148063e+00  8.38789952e-01\n",
      "   1.12601011e-02  1.18817561e-02]\n",
      " [ 4.06018038e-03  1.34105794e-02 -2.74486219e-01  6.99952690e-01\n",
      "  -2.07383074e-02  1.61808592e-02]\n",
      " [-1.04386605e-02 -2.11759873e-02  1.01133845e+00  5.21578639e-01\n",
      "  -3.21893858e-02 -1.99018488e-04]]\n",
      "best candidates so far: ['ry0', 'cnot01', 'cnot01']\n",
      "corresponding weights for each gate: [-1.081480634636772, 0.0, 0.0]\n",
      "----------epoch 140-----------\n",
      "batched average loss:  0.0346373069235024\n",
      "strcuture parameter: \n",
      " [[-0.76373034 -0.45078055  2.0399524   1.21096976 -0.41573595 -0.35985307\n",
      "  -0.34781171 -1.40640614]\n",
      " [-0.5059546  -0.1129814   0.71347997  0.82462464 -0.0974048  -0.10954836\n",
      "   2.45616616 -1.02996471]\n",
      " [-0.96860445 -0.49239049  2.23493873 -0.09638191 -0.41339383 -0.44982767\n",
      "   1.54318662 -0.86056147]] \n",
      " network parameter: \n",
      " [[-1.74433665e-02  7.75381377e-04 -1.42233307e+00  1.38461173e+00\n",
      "   6.82197739e-03  7.73184862e-03]\n",
      " [ 5.58769745e-04  1.24230532e-02 -4.07377212e-01  9.95729650e-01\n",
      "  -4.68752863e-02 -2.26424322e-02]\n",
      " [-5.82361955e-03 -4.07442284e-02  1.31698483e+00  3.71298030e-01\n",
      "  -2.61716641e-02 -2.44514483e-02]]\n",
      "best candidates so far: ['ry0', 'cnot01', 'ry0']\n",
      "corresponding weights for each gate: [-1.422333066088228, 0.0, 1.316984831045342]\n",
      "----------epoch 210-----------\n",
      "batched average loss:  0.02916718918837783\n",
      "strcuture parameter: \n",
      " [[-0.77519833 -0.46711067  2.03648823  1.23699064 -0.43814452 -0.38225816\n",
      "  -0.35835581 -1.44816544]\n",
      " [-0.48640374 -0.09583578  0.71133889  0.83259196 -0.07401868 -0.10253661\n",
      "   2.44776599 -1.04231459]\n",
      " [-0.95255855 -0.4852112   2.23129343 -0.11715594 -0.41835917 -0.44565372\n",
      "   1.55248313 -0.85672219]] \n",
      " network parameter: \n",
      " [[-0.01585351  0.00577482 -1.40401055  1.37815313  0.01131138  0.01219988]\n",
      " [ 0.00484577  0.01058346 -0.38928422  0.98287067 -0.06027619 -0.00580337]\n",
      " [-0.00208013 -0.04564183  1.29845922  0.314766   -0.01635329 -0.00770302]]\n",
      "best candidates so far: ['ry0', 'cnot01', 'ry0']\n",
      "corresponding weights for each gate: [-1.4040105532429732, 0.0, 1.2984592186512862]\n",
      "----------epoch 280-----------\n",
      "batched average loss:  0.02340986490631681\n",
      "strcuture parameter: \n",
      " [[-0.79303073 -0.4872379   2.06364812  1.23260298 -0.46037206 -0.40448471\n",
      "  -0.37555104 -1.4753158 ]\n",
      " [-0.4871502  -0.09756288  0.7004349   0.8084052  -0.07795581 -0.10813278\n",
      "   2.46427986 -1.04461888]\n",
      " [-0.96169755 -0.4986625   2.24012214 -0.14588821 -0.43414211 -0.46182609\n",
      "   1.54917867 -0.84436807]] \n",
      " network parameter: \n",
      " [[-1.91125305e-02  5.80405641e-03 -1.40303855e+00  1.37893166e+00\n",
      "   1.14651923e-02  1.23565328e-02]\n",
      " [ 6.04499973e-04  1.58134092e-02 -3.83435518e-01  9.69193906e-01\n",
      "  -4.11666711e-02 -2.13079003e-02]\n",
      " [-7.52386005e-03 -4.12387461e-02  1.29417092e+00  2.74032945e-01\n",
      "  -2.49211435e-02 -2.48173441e-02]]\n",
      "best candidates so far: ['ry0', 'cnot01', 'ry0']\n",
      "corresponding weights for each gate: [-1.4030385455000842, 0.0, 1.2941709176634286]\n",
      "----------epoch 350-----------\n",
      "batched average loss:  0.03160697523811587\n",
      "strcuture parameter: \n",
      " [[-0.80416752 -0.49854327  2.05638207  1.25706535 -0.47187141 -0.41598553\n",
      "  -0.38660463 -1.51886518]\n",
      " [-0.46472985 -0.07500548  0.70683114  0.81855719 -0.05491497 -0.0869043\n",
      "   2.45048477 -1.06265175]\n",
      " [-0.94101187 -0.47848435  2.22989846 -0.14830581 -0.41456749 -0.4424227\n",
      "   1.55901484 -0.84870187]] \n",
      " network parameter: \n",
      " [[-1.84994776e-02  3.26271608e-03 -1.39540240e+00  1.37528987e+00\n",
      "   9.28585150e-03  1.01706111e-02]\n",
      " [ 8.69785098e-04  1.44480833e-02 -3.75997303e-01  9.65715408e-01\n",
      "  -4.71244188e-02 -1.95782811e-02]\n",
      " [-6.85295994e-03 -4.14117786e-02  1.27972497e+00  2.49409386e-01\n",
      "  -2.21706699e-02 -2.03945780e-02]]\n",
      "best candidates so far: ['ry0', 'cnot01', 'ry0']\n",
      "corresponding weights for each gate: [-1.395402403180499, 0.0, 1.2797249719209864]\n",
      "----------epoch 420-----------\n",
      "batched average loss:  0.006665659245854983\n",
      "strcuture parameter: \n",
      " [[-0.80586133 -0.50160235  2.06065166  1.25635987 -0.47460309 -0.41871846\n",
      "  -0.38731566 -1.53636096]\n",
      " [-0.46114019 -0.07367434  0.69956382  0.80732272 -0.05621184 -0.0879927\n",
      "   2.45863338 -1.07319266]\n",
      " [-0.9517928  -0.48919892  2.24097649 -0.16736005 -0.42631251 -0.45848482\n",
      "   1.55049099 -0.84819656]] \n",
      " network parameter: \n",
      " [[-1.84850357e-02  6.72421594e-03 -1.39244807e+00  1.37273932e+00\n",
      "   8.36196055e-03  9.24300262e-03]\n",
      " [ 1.38569531e-03  1.52976956e-02 -3.71336219e-01  9.59169559e-01\n",
      "  -4.71825227e-02 -1.72672440e-02]\n",
      " [-4.53611012e-03 -4.25709793e-02  1.27903734e+00  2.29834603e-01\n",
      "  -2.15456544e-02 -1.70882048e-02]]\n",
      "best candidates so far: ['ry0', 'cnot01', 'ry0']\n",
      "corresponding weights for each gate: [-1.3924480674638928, 0.0, 1.2790373368849457]\n",
      "----------epoch 490-----------\n",
      "batched average loss:  0.020461205600274406\n",
      "strcuture parameter: \n",
      " [[-0.8244069  -0.5214151   2.0752534   1.26389091 -0.49462964 -0.43874501\n",
      "  -0.4051159  -1.56853363]\n",
      " [-0.47115165 -0.08366402  0.69328056  0.79660862 -0.06568442 -0.10022959\n",
      "   2.4712661  -1.08985123]\n",
      " [-0.94650374 -0.48598675  2.23897085 -0.17417499 -0.42431066 -0.45578272\n",
      "   1.55152605 -0.83376933]] \n",
      " network parameter: \n",
      " [[-0.01928944  0.00499368 -1.3947106   1.37519503  0.00848746  0.00937435]\n",
      " [ 0.0018318   0.01397172 -0.37201866  0.95742861 -0.04425313 -0.01833834]\n",
      " [-0.00537032 -0.04237466  1.27465625  0.21556398 -0.02131689 -0.01945358]]\n",
      "best candidates so far: ['ry0', 'cnot01', 'ry0']\n",
      "corresponding weights for each gate: [-1.3947106020683582, 0.0, 1.274656245510708]\n",
      "----------epoch 560-----------\n",
      "batched average loss:  0.023328921635492113\n",
      "strcuture parameter: \n",
      " [[-0.82938612 -0.52639869  2.09003233  1.2549719  -0.50027072 -0.44438196\n",
      "  -0.40978915 -1.58478662]\n",
      " [-0.46080745 -0.07270394  0.6974805   0.78091747 -0.055056   -0.09048302\n",
      "   2.47426546 -1.0919247 ]\n",
      " [-0.95053196 -0.49146487  2.2438882  -0.19065999 -0.42940408 -0.46024591\n",
      "   1.55006514 -0.83800116]] \n",
      " network parameter: \n",
      " [[-0.01768402  0.00864682 -1.39186924  1.37279304  0.01043867  0.0113236 ]\n",
      " [ 0.00196044  0.01785915 -0.36908583  0.9503536  -0.04221657 -0.01665966]\n",
      " [-0.00567682 -0.04012372  1.27271281  0.20027357 -0.02340885 -0.01890264]]\n",
      "best candidates so far: ['ry0', 'cnot01', 'ry0']\n",
      "corresponding weights for each gate: [-1.3918692382707931, 0.0, 1.2727128067830515]\n",
      "----------epoch 630-----------\n",
      "batched average loss:  0.022294904366186336\n",
      "strcuture parameter: \n",
      " [[-0.82124923 -0.51895758  2.07264382  1.26825732 -0.49235075 -0.4364652\n",
      "  -0.40155702 -1.62107966]\n",
      " [-0.44077094 -0.05357257  0.6950399   0.78544649 -0.0352301  -0.07051406\n",
      "   2.46720079 -1.12742085]\n",
      " [-0.96508586 -0.50568689  2.26336968 -0.21831926 -0.44404717 -0.47502318\n",
      "   1.53544765 -0.86546517]] \n",
      " network parameter: \n",
      " [[-0.01822958  0.00400422 -1.38537983  1.36788631  0.0089444   0.00982374]\n",
      " [ 0.00164439  0.01401018 -0.36291978  0.94651475 -0.04138315 -0.01835733]\n",
      " [-0.00633653 -0.04123063  1.27162353  0.18400016 -0.02248301 -0.0205508 ]]\n",
      "best candidates so far: ['ry0', 'cnot01', 'ry0']\n",
      "corresponding weights for each gate: [-1.385379827529656, 0.0, 1.271623530452604]\n",
      "----------epoch 699-----------\n",
      "batched average loss:  0.008617433180671905\n",
      "strcuture parameter: \n",
      " [[-0.8330096  -0.53062558  2.09200324  1.26080791 -0.50406188 -0.44817444\n",
      "  -0.413163   -1.63969549]\n",
      " [-0.42837574 -0.04133071  0.70613048  0.77956012 -0.02271508 -0.05842368\n",
      "   2.46303776 -1.1335837 ]\n",
      " [-0.95399718 -0.49508285  2.25531308 -0.22080434 -0.43332773 -0.46424763\n",
      "   1.54531494 -0.87047985]] \n",
      " network parameter: \n",
      " [[-1.63048132e-02  1.34069499e-03 -1.38491048e+00  1.36807570e+00\n",
      "   9.47264822e-03  1.03543277e-02]\n",
      " [ 2.47320980e-03  1.32809648e-02 -3.62564573e-01  9.43326996e-01\n",
      "  -4.40426259e-02 -1.62040079e-02]\n",
      " [-6.33182984e-03 -4.06440282e-02  1.26846462e+00  1.75565645e-01\n",
      "  -2.25908296e-02 -1.99152133e-02]]\n",
      "best candidates so far: ['ry0', 'cnot01', 'ry0']\n",
      "corresponding weights for each gate: [-1.3849104829435666, 0.0, 1.2684646159137885]\n"
     ]
    }
   ],
   "source": [
    "verbose = True\n",
    "epochs = 700\n",
    "lr = tf.keras.optimizers.schedules.ExponentialDecay(0.05, 200, 0.5)\n",
    "structure_opt = tc.backend.optimizer(tf.keras.optimizers.Adam(0.04))\n",
    "network_opt = tc.backend.optimizer(tf.keras.optimizers.Adam(lr))\n",
    "nnp = K.implicit_randn(stddev=0.02, shape=[p, 6], dtype=rtype)\n",
    "stp = K.implicit_randn(stddev=0.02, shape=[p, 8], dtype=rtype)\n",
    "for epoch in range(epochs):\n",
    "    infd, (gnnp, gstp) = vag2(nnp, stp)\n",
    "\n",
    "    nnp = network_opt.update(gnnp, nnp)\n",
    "    stp = structure_opt.update(gstp, stp)\n",
    "    if epoch % 70 == 0 or epoch == epochs - 1:\n",
    "        print(\"----------epoch %s-----------\" % epoch)\n",
    "        print(\n",
    "            \"batched average loss: \",\n",
    "            np.mean(infd),\n",
    "        )\n",
    "        if verbose:\n",
    "            print(\n",
    "                \"strcuture parameter: \\n\",\n",
    "                stp.numpy(),\n",
    "                \"\\n network parameter: \\n\",\n",
    "                nnp.numpy(),\n",
    "            )\n",
    "\n",
    "        cand_preset = best_from_structure(stp)\n",
    "        print(\"best candidates so far:\", [ops_repr[i] for i in cand_preset])\n",
    "        print(\n",
    "            \"corresponding weights for each gate:\",\n",
    "            [K.numpy(nnp[j, i]) if i < 6 else 0.0 for j, i in enumerate(cand_preset)],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 8), dtype=float32, numpy=\n",
       "array([[[0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_structure = K.onehot(np.array([2, 4, 6]), num=8)\n",
    "chosen_structure = K.reshape(chosen_structure, [1, p, ch])\n",
    "chosen_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss:  0.9644019550577962\n",
      "60 loss:  0.8989188689211314\n",
      "120 loss:  0.8298012603554974\n",
      "180 loss:  0.7560331634927562\n",
      "240 loss:  0.6779941679539283\n",
      "300 loss:  0.5961486934180202\n",
      "360 loss:  0.5110284342535933\n",
      "420 loss:  0.4232176451899497\n",
      "480 loss:  0.33333753027426183\n",
      "540 loss:  0.24203042848994694\n",
      "600 loss:  0.14994446358149527\n",
      "660 loss:  0.05771922041773825\n",
      "720 loss:  0.001956006605030141\n",
      "780 loss:  0.00031044641307371524\n",
      "840 loss:  0.0002432198430751021\n",
      "900 loss:  0.00021240388204815484\n",
      "960 loss:  0.0001003711168773016\n",
      "999 loss:  0.00011424485522940562\n"
     ]
    }
   ],
   "source": [
    "network_opt = tc.backend.optimizer(tf.keras.optimizers.Adam(1e-3))\n",
    "nnp = K.implicit_randn(stddev=0.02, shape=[p, 6], dtype=rtype)\n",
    "verbose = True\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    infd, gnnp = vag1(nnp, chosen_structure)\n",
    "    nnp = network_opt.update(gnnp, nnp)\n",
    "    if epoch % 60 == 0 or epoch == epochs - 1:\n",
    "        print(epoch, \"loss: \", K.numpy(infd[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
