{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mindquantum.core.gates import RX, RY, RZ, H, X, Y, Z, CNOT\n",
    "from mindquantum.core.circuit import Circuit\n",
    "import mindspore as ms\n",
    "from mindquantum.simulator import  Simulator\n",
    "from mindquantum.core.gates import GroupedPauli\n",
    "from mindquantum.core.operators import TimeEvolution,QubitOperator\n",
    "from mindquantum.core.parameterresolver import PRConvertible,PRGenerator,ParameterResolver\n",
    "from DQAS_tool import generate_pauli_string,one_hot\n",
    "from mindquantum.core.gates import RotPauliString\n",
    "from mindquantum.core.gates import UnivMathGate\n",
    "from mindspore import Tensor, ops\n",
    "from mindquantum.core.circuit import UN\n",
    "from mindquantum.core.operators import Hamiltonian             # 导入Hamiltonian模块，用于构建哈密顿量\n",
    "from mindquantum.framework import MQLayer\n",
    "from mindspore.nn import  TrainOneStepCell\n",
    "from mindspore.nn import SoftmaxCrossEntropyWithLogits                         # 导入SoftmaxCrossEntropyWithLogits模块，用于定义损失函数\n",
    "from mindspore.nn import Adam                                                  # 导入Adam模块用于定义优化参数\n",
    "from mindspore.train import Accuracy, Model, LossMonitor                       # 导入Accuracy模块，用于评估预测准确率\n",
    "import mindspore as ms\n",
    "from mindspore import Parameter, Tensor\n",
    "from mindspore.dataset import NumpySlicesDataset\n",
    "from torch.utils.data import DataLoader# 导入NumpySlicesDataset模块，用于创建模型可以识别的数据集\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from data_processing import X_train,X_test,y_train,y_test\n",
    "num_layer = 3\n",
    "# 定义标准差和形状\n",
    "stddev = 0.02\n",
    "shape_nnp = (num_layer, 8)\n",
    "shape_stp = (num_layer, 12)\n",
    "\n",
    "rtype = np.float64\n",
    "ctype = np.complex128\n",
    "# 使用 numpy 生成随机数矩阵\n",
    "nnp = np.random.normal(loc=0.0, scale=stddev, size=shape_nnp).astype(rtype)\n",
    "stp = np.random.normal(loc=0.0, scale=stddev, size=shape_stp).astype(rtype)\n",
    "#Operator Pool\n",
    "unbound_opeartor_pool = [generate_pauli_string(n=8,seed=i)[0] for i in range(8)]\n",
    "bound_opeartor_pool = [generate_pauli_string(n=8,seed=i)[1] for i in range(8,12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindquantum.core.gates import  gene_univ_parameterized_gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 YZIYYXXY\n",
      "1 IZZYYXZI\n",
      "2 XIIXYIIZ\n",
      "3 IIIYYIYX\n"
     ]
    }
   ],
   "source": [
    "for index_op,each_op in enumerate(bound_opeartor_pool):\n",
    "    print(index_op,each_op)\n",
    "    op = GroupedPauli(each_op)\n",
    "    tmp_cir = Circuit([GroupedPauli(each_op).on(range(8))])\n",
    "    matrix = tmp_cir.matrix()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_ghz_state(num_bits):\n",
    "    # 创建一个包含 2^num_bits 个元素的零向量\n",
    "    ghz_state = np.zeros((2**num_bits,), dtype=np.complex128)\n",
    "    \n",
    "    # 设置第一个元素为 |000...0>，第二个元素为 |111...1>\n",
    "    ghz_state[0] = 1  # |000...0>\n",
    "    ghz_state[-1] = 1  # |111...1>\n",
    "    \n",
    "    # 归一化\n",
    "    ghz_state /= np.sqrt(2)\n",
    "    \n",
    "    return ghz_state\n",
    "\n",
    "ghz_8_qbits = generate_ghz_state(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForwardAndLoss(ms.nn.Cell):\n",
    "    def __init__(self, backbone, loss_fn):\n",
    "        super(ForwardAndLoss, self).__init__(auto_prefix=False)\n",
    "        self.backbone = backbone\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def construct(self, data, label):\n",
    "        output = self.backbone(data)\n",
    "        return self.loss_fn(output, label)\n",
    "\n",
    "    def backbone_network(self):\n",
    "        return self.backbone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import nn\n",
    "def Mindspore_ansatz(Structure_p:Parameter,Ansatz_p:Parameter,n_layer:int,n_qbits:int=8):\n",
    "    \"\"\"\n",
    "    和 DQAS 文章描述的一致，生成权重线路\n",
    "    Structure_p:np.array DQAS中的权重参数,\n",
    "    Ansatz_p:np.array  DQAS中的Ansatz参数,\n",
    "    \n",
    "    \"\"\"\n",
    "    Structure_p = Parameter(Tensor(Structure_p, ms.float32), requires_grad=True)\n",
    "    #Ansatz_p = Parameter(Tensor(Ansatz_p, ms.float32), requires_grad=True)\n",
    "    softmax = ops.Softmax()\n",
    "    my_stp = softmax(Tensor(Structure_p, ms.float32))\n",
    "    ansatz = Circuit()\n",
    "    pr_gen = PRGenerator('ansatz')\n",
    "    \n",
    "    for i in range(n_layer):\n",
    "        paramertized_part_count=0\n",
    "        for index_op,each_op in enumerate(unbound_opeartor_pool):\n",
    "            # ansatz_param = Ansatz_p[i,index_op]\n",
    "            #Structure_param =float(stp[i,index_op])\n",
    "            ansatz += TimeEvolution(QubitOperator(terms=each_op,coefficient=pr_gen.new()),time=float(my_stp[i,index_op])).circuit\n",
    "            paramertized_part_count+=1\n",
    "            \n",
    "        for index_op,each_op in enumerate(bound_opeartor_pool):\n",
    "            #print(index_op,each_op,paramertized_part_count)\n",
    "            op = GroupedPauli(each_op)\n",
    "            tmp_cir = Circuit([GroupedPauli(each_op).on(range(n_qbits))])\n",
    "            matrix = tmp_cir.matrix()\n",
    "            #print(matrix.shape,my_stp[i,index_op+paramertized_part_count])\n",
    "            ansatz += UnivMathGate(matrix_value=matrix*float(my_stp[i,index_op+paramertized_part_count]),name=op.pauli_string).on(range(n_qbits))  \n",
    "            \n",
    "    sim = Simulator(backend='mqvector',n_qubits=8)\n",
    "    hams = [Hamiltonian(QubitOperator(f'Z{i}')) for i in [0,1]]\n",
    "    grad_ops= sim.get_expectation_with_grad(hams,ansatz)\n",
    "    QuantumNet = MQLayer(grad_ops)   \n",
    "    loss = ms.nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean') \n",
    "    net_with_loss = ForwardAndLoss(QuantumNet, loss)\n",
    "    # grad = ms.ops.GradOperation(get_by_list=True)\n",
    "    \n",
    "    \n",
    "        # 计算 loss 和 ansatz_parameter 的梯度\n",
    "    class GradientCalculator(nn.Cell):\n",
    "        def __init__(self, network, weights):\n",
    "            super(GradientCalculator, self).__init__()\n",
    "            self.network = network\n",
    "            self.weights = weights\n",
    "            self.grad = ops.GradOperation(get_by_list=True)\n",
    "\n",
    "        def construct(self, data, label):\n",
    "            loss = self.network(data, label)\n",
    "            grads = self.grad(self.network, self.weights)(data, label)\n",
    "            return loss, grads\n",
    "\n",
    "    # 定义结构参数和 ansatz 参数的权重\n",
    "    weights = [Parameter(Tensor(Ansatz_p, ms.float32), requires_grad=True)]\n",
    "    grad_calculator = GradientCalculator(net_with_loss, weights)\n",
    "    \n",
    "    # loss_value = net_with_loss(X_train, y_train)\n",
    "    \n",
    "    # grads = grad(self.network, weights)(data, label)\n",
    "    \n",
    "    return ansatz, grad_calculator\n",
    "            \n",
    "    # sim = Simulator(backend='mqvector',n_qubits=8)\n",
    "    # sim.apply_circuit(ansatz,pr=Ansatz_p.reshape(-1))\n",
    "    # state =  sim.get_qs()\n",
    "    # target_tensor = ms.Tensor(ghz_8_qbits, dtype=ms.float32)\n",
    "    # state_tensor = ms.Tensor(state, dtype=ms.float32)\n",
    "    # loss = sum(ops.abs(target_tensor-state_tensor))\n",
    "    # return loss\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "ansatz,gr = Mindspore_ansatz(Structure_p=stp,Ansatz_p=nnp,n_layer=3,n_qbits=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Encoder data requires a two dimension Tensor with second dimension should be 0, but get shape (3, 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[138], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 假设 X_train 和 y_train 已经定义好\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m loss_value, ansatz_grads \u001b[38;5;241m=\u001b[39m \u001b[43mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnnp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/MindSpore/lib/python3.9/site-packages/mindspore/nn/cell.py:705\u001b[0m, in \u001b[0;36mCell.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    704\u001b[0m     _pynative_executor\u001b[38;5;241m.\u001b[39mclear_res()\n\u001b[0;32m--> 705\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Parameter):\n\u001b[1;32m    708\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mdata\n",
      "File \u001b[0;32m/opt/miniconda3/envs/MindSpore/lib/python3.9/site-packages/mindspore/nn/cell.py:701\u001b[0m, in \u001b[0;36mCell.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    700\u001b[0m     _pynative_executor\u001b[38;5;241m.\u001b[39mnew_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 701\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_construct\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m     _pynative_executor\u001b[38;5;241m.\u001b[39mend_graph(\u001b[38;5;28mself\u001b[39m, output, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/MindSpore/lib/python3.9/site-packages/mindspore/nn/cell.py:482\u001b[0m, in \u001b[0;36mCell._run_construct\u001b[0;34m(self, cast_inputs, kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shard_fn(\u001b[38;5;241m*\u001b[39mcast_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 482\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcast_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_forward_hook:\n\u001b[1;32m    484\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_forward_hook(cast_inputs, output)\n",
      "Cell \u001b[0;32mIn[131], line 50\u001b[0m, in \u001b[0;36mMindspore_ansatz.<locals>.GradientCalculator.construct\u001b[0;34m(self, data, label)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstruct\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, label):\n\u001b[0;32m---> 50\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights)(data, label)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss, grads\n",
      "File \u001b[0;32m/opt/miniconda3/envs/MindSpore/lib/python3.9/site-packages/mindspore/nn/cell.py:705\u001b[0m, in \u001b[0;36mCell.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    704\u001b[0m     _pynative_executor\u001b[38;5;241m.\u001b[39mclear_res()\n\u001b[0;32m--> 705\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Parameter):\n\u001b[1;32m    708\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mdata\n",
      "File \u001b[0;32m/opt/miniconda3/envs/MindSpore/lib/python3.9/site-packages/mindspore/nn/cell.py:701\u001b[0m, in \u001b[0;36mCell.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    700\u001b[0m     _pynative_executor\u001b[38;5;241m.\u001b[39mnew_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 701\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_construct\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m     _pynative_executor\u001b[38;5;241m.\u001b[39mend_graph(\u001b[38;5;28mself\u001b[39m, output, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/MindSpore/lib/python3.9/site-packages/mindspore/nn/cell.py:482\u001b[0m, in \u001b[0;36mCell._run_construct\u001b[0;34m(self, cast_inputs, kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shard_fn(\u001b[38;5;241m*\u001b[39mcast_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 482\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcast_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_forward_hook:\n\u001b[1;32m    484\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_forward_hook(cast_inputs, output)\n",
      "Cell \u001b[0;32mIn[123], line 8\u001b[0m, in \u001b[0;36mForwardAndLoss.construct\u001b[0;34m(self, data, label)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstruct\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, label):\n\u001b[0;32m----> 8\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(output, label)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/MindSpore/lib/python3.9/site-packages/mindspore/nn/cell.py:705\u001b[0m, in \u001b[0;36mCell.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    704\u001b[0m     _pynative_executor\u001b[38;5;241m.\u001b[39mclear_res()\n\u001b[0;32m--> 705\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Parameter):\n\u001b[1;32m    708\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mdata\n",
      "File \u001b[0;32m/opt/miniconda3/envs/MindSpore/lib/python3.9/site-packages/mindspore/nn/cell.py:701\u001b[0m, in \u001b[0;36mCell.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    700\u001b[0m     _pynative_executor\u001b[38;5;241m.\u001b[39mnew_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 701\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_construct\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m     _pynative_executor\u001b[38;5;241m.\u001b[39mend_graph(\u001b[38;5;28mself\u001b[39m, output, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/MindSpore/lib/python3.9/site-packages/mindspore/nn/cell.py:482\u001b[0m, in \u001b[0;36mCell._run_construct\u001b[0;34m(self, cast_inputs, kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shard_fn(\u001b[38;5;241m*\u001b[39mcast_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 482\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcast_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_forward_hook:\n\u001b[1;32m    484\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_forward_hook(cast_inputs, output)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/MindSpore/lib/python3.9/site-packages/mindquantum/framework/layer.py:94\u001b[0m, in \u001b[0;36mMQLayer.construct\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstruct\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg):\n\u001b[1;32m     93\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Construct a MQLayer node.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevolution\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/MindSpore/lib/python3.9/site-packages/mindspore/nn/cell.py:705\u001b[0m, in \u001b[0;36mCell.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    704\u001b[0m     _pynative_executor\u001b[38;5;241m.\u001b[39mclear_res()\n\u001b[0;32m--> 705\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Parameter):\n\u001b[1;32m    708\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mdata\n",
      "File \u001b[0;32m/opt/miniconda3/envs/MindSpore/lib/python3.9/site-packages/mindspore/nn/cell.py:701\u001b[0m, in \u001b[0;36mCell.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    700\u001b[0m     _pynative_executor\u001b[38;5;241m.\u001b[39mnew_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 701\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_construct\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m     _pynative_executor\u001b[38;5;241m.\u001b[39mend_graph(\u001b[38;5;28mself\u001b[39m, output, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/MindSpore/lib/python3.9/site-packages/mindspore/nn/cell.py:482\u001b[0m, in \u001b[0;36mCell._run_construct\u001b[0;34m(self, cast_inputs, kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shard_fn(\u001b[38;5;241m*\u001b[39mcast_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 482\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcast_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_forward_hook:\n\u001b[1;32m    484\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_forward_hook(cast_inputs, output)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/MindSpore/lib/python3.9/site-packages/mindquantum/framework/operations.py:134\u001b[0m, in \u001b[0;36mMQOps.construct\u001b[0;34m(self, enc_data, ans_data)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstruct\u001b[39m(\u001b[38;5;28mself\u001b[39m, enc_data, ans_data):\n\u001b[1;32m    133\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Construct an MQOps node.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     \u001b[43mcheck_enc_input_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape_ops\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpectation_with_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder_params_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m     check_ans_input_shape(ans_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_ops(ans_data), \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpectation_with_grad\u001b[38;5;241m.\u001b[39mansatz_params_name))\n\u001b[1;32m    136\u001b[0m     fval, g_enc, g_ans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpectation_with_grad(enc_data\u001b[38;5;241m.\u001b[39masnumpy(), ans_data\u001b[38;5;241m.\u001b[39masnumpy())\n",
      "File \u001b[0;32m/opt/miniconda3/envs/MindSpore/lib/python3.9/site-packages/mindspore/ops/primitive.py:825\u001b[0m, in \u001b[0;36mconstexpr.<locals>.deco.<locals>.CompileOp.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/MindSpore/lib/python3.9/site-packages/mindquantum/framework/operations.py:38\u001b[0m, in \u001b[0;36mcheck_enc_input_shape\u001b[0;34m(data, encoder_tensor, enc_len)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoder parameter requires a Tensor but get \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_tensor) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m encoder_tensor[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m enc_len:\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEncoder data requires a two dimension Tensor with second\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m dimension should be \u001b[39m\u001b[38;5;132;01m{\u001b[39;00menc_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but get shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mencoder_tensor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     41\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Encoder data requires a two dimension Tensor with second dimension should be 0, but get shape (3, 8)"
     ]
    }
   ],
   "source": [
    "# 假设 X_train 和 y_train 已经定义好\n",
    "loss_value, ansatz_grads = gr(Tensor(nnp, ms.float32), Tensor(y_train, ms.int32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1,\n",
       "  Tensor(shape=[2], dtype=Float32, value= [ 7.50000000e+01,  7.50000000e+01])),\n",
       " (2,\n",
       "  Tensor(shape=[2], dtype=Float32, value= [ 3.00000000e+01,  3.00000000e+01])))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def fn(x, y, z):\n",
    "    res = x * ops.exp(y) * ops.pow(z, 2)\n",
    "    return res, z\n",
    "\n",
    "x = Tensor([3, 3], ms.float32)\n",
    "y = Tensor([0, 0], ms.float32)\n",
    "z = Tensor([5, 5], ms.float32)\n",
    "gradient, aux = grad(fn, (1, 2), None, True,True)(x, y, z)\n",
    "gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tensor(shape=[2], dtype=Float32, value= [ 5.00000000e+00,  5.00000000e+00]),)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[163], line 11\u001b[0m\n",
      "\u001b[1;32m      8\u001b[0m vag2 \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mvalue_and_grad(fn\u001b[38;5;241m=\u001b[39mwrapped_mindspore_ansatz, grad_position\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# 使用 vag2 计算损失及其对 Structure_p 和 Ansatz_p 的梯度\u001b[39;00m\n",
      "\u001b[0;32m---> 11\u001b[0m loss_value, (grad_structure, grad_ansatz) \u001b[38;5;241m=\u001b[39m vag2(stp, nnp)  \u001b[38;5;66;03m# 确保 stp 和 nnp 是 numpy array\u001b[39;00m\n",
      "\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss Value:\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss_value)\n",
      "\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGradient for Structure_p:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grad_structure)\n",
      "\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "nnp = np.random.normal(loc=0.0, scale=stddev, size=shape_nnp).astype(rtype)\n",
    "stp = np.random.normal(loc=0.0, scale=stddev, size=shape_stp).astype(rtype)\n",
    "\n",
    "def wrapped_mindspore_ansatz(Structure_p, Ansatz_p, n_layer=3, n_qbits=8):\n",
    "    return Mindspore_ansatz(Structure_p, Ansatz_p, n_layer=n_layer, n_qbits=n_qbits)\n",
    "\n",
    "# 创建带梯度计算的函数\n",
    "vag2 = ops.value_and_grad(fn=wrapped_mindspore_ansatz, grad_position=(0, 1))\n",
    "\n",
    "# 使用 vag2 计算损失及其对 Structure_p 和 Ansatz_p 的梯度\n",
    "loss_value, (grad_structure, grad_ansatz) = vag2(stp, nnp)  # 确保 stp 和 nnp 是 numpy array\n",
    "print(\"Loss Value:\", loss_value)\n",
    "print(\"Gradient for Structure_p:\", grad_structure)\n",
    "print(\"Gradient for Ansatz_p:\", grad_ansatz)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[], dtype=Float32, value= 1.41421)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mindspore_ansatz(stp,nnp,3,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tensor(shape=[], dtype=Float32, value= 1.00708), ())"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vag2(stp,nnp,3,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "too many positional arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m vag2 \u001b[38;5;241m=\u001b[39m ms\u001b[38;5;241m.\u001b[39mvalue_and_grad(Mindspore_ansatz, grad_position\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# 使用示例\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m loss_value, gradients \u001b[38;5;241m=\u001b[39m \u001b[43mvag2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mStructure_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAnsatz_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_qbits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# print(\"Loss:\", loss_value)\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# print(\"Gradients:\", gradients)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/MindSpore/lib/python3.9/site-packages/mindspore/ops/composite/base.py:621\u001b[0m, in \u001b[0;36m_Grad.__call__.<locals>.after_grad\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mafter_grad\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgrad_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_position\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/MindSpore/lib/python3.9/site-packages/mindspore/common/api.py:121\u001b[0m, in \u001b[0;36m_wrap_func.<locals>.wrapper\u001b[0;34m(*arg, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39marg, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 121\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _convert_python_data(results)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/MindSpore/lib/python3.9/site-packages/mindspore/ops/composite/base.py:600\u001b[0m, in \u001b[0;36m_Grad.__call__.<locals>.after_grad\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;129m@_wrap_func\u001b[39m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mafter_grad\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 600\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pynative_forward_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m     _pynative_executor\u001b[38;5;241m.\u001b[39mgrad(fn, grad_, weights, grad_position, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    602\u001b[0m     out \u001b[38;5;241m=\u001b[39m _pynative_executor()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/MindSpore/lib/python3.9/site-packages/mindspore/ops/composite/base.py:650\u001b[0m, in \u001b[0;36m_Grad._pynative_forward_run\u001b[0;34m(self, fn, grad, weights, args, kwargs)\u001b[0m\n\u001b[1;32m    648\u001b[0m _pynative_executor\u001b[38;5;241m.\u001b[39mset_grad_flag(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    649\u001b[0m _pynative_executor\u001b[38;5;241m.\u001b[39mnew_graph(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_kwargs)\n\u001b[0;32m--> 650\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m _pynative_executor\u001b[38;5;241m.\u001b[39mend_graph(fn, outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_kwargs)\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "Cell \u001b[0;32mIn[49], line 48\u001b[0m, in \u001b[0;36mMindspore_ansatz\u001b[0;34m(Structure_p, Ansatz_p, n_layer, n_qbits)\u001b[0m\n\u001b[1;32m     46\u001b[0m target_tensor \u001b[38;5;241m=\u001b[39m Tensor(ghz_8_qbits, dtype\u001b[38;5;241m=\u001b[39mms\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     47\u001b[0m state_tensor \u001b[38;5;241m=\u001b[39m Tensor(state, dtype\u001b[38;5;241m=\u001b[39mms\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 48\u001b[0m loss \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mReduceSum(\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAbs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_tensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstate_tensor\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/opt/miniconda3/envs/MindSpore/lib/python3.9/site-packages/mindspore/ops/primitive.py:725\u001b[0m, in \u001b[0;36mprim_attr_register.<locals>.deco\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    724\u001b[0m     Primitive\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m--> 725\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m bound_args\u001b[38;5;241m.\u001b[39mapply_defaults()\n\u001b[1;32m    727\u001b[0m arguments \u001b[38;5;241m=\u001b[39m bound_args\u001b[38;5;241m.\u001b[39marguments\n",
      "File \u001b[0;32m/opt/miniconda3/envs/MindSpore/lib/python3.9/inspect.py:3045\u001b[0m, in \u001b[0;36mSignature.bind\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3040\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3041\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[1;32m   3042\u001b[0m \u001b[38;5;124;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[1;32m   3043\u001b[0m \u001b[38;5;124;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[1;32m   3044\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3045\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/MindSpore/lib/python3.9/inspect.py:2966\u001b[0m, in \u001b[0;36mSignature._bind\u001b[0;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[1;32m   2964\u001b[0m     param \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(parameters)\n\u001b[1;32m   2965\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m-> 2966\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoo many positional arguments\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2967\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2968\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m (_VAR_KEYWORD, _KEYWORD_ONLY):\n\u001b[1;32m   2969\u001b[0m         \u001b[38;5;66;03m# Looks like we have no parameter for this positional\u001b[39;00m\n\u001b[1;32m   2970\u001b[0m         \u001b[38;5;66;03m# argument\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: too many positional arguments"
     ]
    }
   ],
   "source": [
    "import mindspore as ms\n",
    "import mindspore.ops as ops\n",
    "from mindspore import Tensor, Parameter\n",
    "from mindquantum import Circuit, Simulator, QubitOperator, TimeEvolution, UnivMathGate\n",
    "\n",
    "# 定义 GHZ 状态\n",
    "\n",
    "ghz_8_qbits = generate_ghz_state(8)\n",
    "num_layer = 3\n",
    "# 定义标准差和形状\n",
    "stddev = 0.02\n",
    "shape_nnp = (num_layer, 8)\n",
    "shape_stp = (num_layer, 12)\n",
    "\n",
    "rtype = np.float64\n",
    "ctype = np.complex128\n",
    "# 使用 numpy 生成随机数矩阵\n",
    "nnp = np.random.normal(loc=0.0, scale=stddev, size=shape_nnp).astype(rtype)\n",
    "stp = np.random.normal(loc=0.0, scale=stddev, size=shape_stp).astype(rtype)\n",
    "\n",
    "def Mindspore_ansatz(Structure_p: Parameter, Ansatz_p: Parameter, n_layer: int=3, n_qbits: int = 8):\n",
    "    softmax = ops.Softmax()\n",
    "    my_stp = softmax(Tensor(Structure_p, ms.float32))\n",
    "    ansatz = Circuit()\n",
    "\n",
    "    for i in range(n_layer):\n",
    "        paramertized_part_count = 0\n",
    "        for index_op, each_op in enumerate(unbound_opeartor_pool):\n",
    "            ansatz += TimeEvolution(QubitOperator(terms=each_op, coefficient=float(Ansatz_p[i, index_op])), \n",
    "                                   time=float(my_stp[i, index_op])).circuit\n",
    "            paramertized_part_count += 1\n",
    "\n",
    "        for index_op, each_op in enumerate(bound_opeartor_pool):\n",
    "            op = GroupedPauli(each_op)\n",
    "            tmp_cir = Circuit([GroupedPauli(each_op).on(range(n_qbits))])\n",
    "            matrix = tmp_cir.matrix()\n",
    "            ansatz += UnivMathGate(matrix_value=matrix * float(my_stp[i, index_op + paramertized_part_count]), \n",
    "                                   name=op.pauli_string).on(range(n_qbits))\n",
    "\n",
    "    # 使用模拟器应用电路\n",
    "    sim = Simulator(backend='mqvector', n_qubits=n_qbits)\n",
    "    sim.apply_circuit(ansatz)\n",
    "    state = sim.get_qs()\n",
    "\n",
    "    # 计算损失\n",
    "    target_tensor = Tensor(ghz_8_qbits, dtype=ms.float32)\n",
    "    state_tensor = Tensor(state, dtype=ms.float32)\n",
    "    loss = ops.ReduceSum(ops.Abs(target_tensor - state_tensor))\n",
    "\n",
    "    return loss\n",
    "\n",
    "# 确保参数被定义为 Parameter 类型，并设置 requires_grad=True\n",
    "Structure_p = Parameter(Tensor(stp), requires_grad=True)  # 你的结构参数\n",
    "Ansatz_p = Parameter(Tensor(nnp), requires_grad=True)      # 你的 Ansatz 参数\n",
    "\n",
    "# 使用 value_and_grad 来计算损失和梯度\n",
    "vag2 = ms.value_and_grad(Mindspore_ansatz, grad_position=(0, 1))\n",
    "\n",
    "# 使用示例\n",
    "loss_value, gradients = vag2(Structure_p, Ansatz_p, n_layer=3, n_qbits=8)\n",
    "\n",
    "# print(\"Loss:\", loss_value)\n",
    "# print(\"Gradients:\", gradients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
