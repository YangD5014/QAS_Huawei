{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                          \n",
    "from mindquantum.core.circuit import Circuit                \n",
    "from mindquantum.core.gates import H, RX, RY, RZ,X    \n",
    "from mindquantum.core.parameterresolver import PRGenerator  \n",
    "from mindquantum.simulator import Simulator\n",
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split   \n",
    "from mindquantum.algorithm.library import amplitude_encoder\n",
    "from mindquantum.algorithm.nisq import HardwareEfficientAnsatz     \n",
    "from mindquantum.core.operators import QubitOperator           # 导入QubitOperator模块，用于构造泡利算符\n",
    "from mindquantum.core.operators import Hamiltonian             # 导入Hamiltonian模块，用于构建哈密顿量\n",
    "import mindspore as ms                                                                         # 导入mindspore库并简写为ms\n",
    "from mindquantum.framework import MQLayer                                                      # 导入MQLayer\n",
    "# 导入HardwareEfficientAnsatz\n",
    "from mindquantum.core.gates import RY           \n",
    "import torch\n",
    "from torchvision import datasets, transforms# 导入量子门RY\n",
    "from scipy.ndimage import zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "def filter_3_and_6(data):\n",
    "    images, labels = data\n",
    "    mask = (labels == 3) | (labels == 6)\n",
    "    return images[mask], labels[mask]\n",
    "\n",
    "mnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "filtered_data = filter_3_and_6((mnist_dataset.data, mnist_dataset.targets))\n",
    "X_data,y = filtered_data #X 图像数据 y 标签\n",
    "# Compressed_X = np.array([zoom(img,0.4) for img in X])\n",
    "# Compressed_X = torch.tensor(Compressed_X, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y, test_size=0.2, random_state=0, shuffle=True) # 将数据集划分为训练集和测试集\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "print(X_train.shape)                                                                                   # 打印训练集中样本的数据类型\n",
    "print(X_test.shape)                                                                                    # 打印测试集中样本的数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, parameterResolver  = amplitude_encoder(X_train[0].numpy().flatten(),10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prg = PRGenerator('alpha')\n",
    "# encoder = Circuit()\n",
    "sim = Simulator('mqvector', 10)\n",
    "encoder, parameterResolver  = amplitude_encoder(X_train[0].numpy().flatten(),9)    \n",
    "encoder = encoder.no_grad() \n",
    "# sim.apply_circuit(circuit=encoder,pr=parameterResolver)\n",
    "# result = sim.get_qs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ansatz = HardwareEfficientAnsatz(10, single_rot_gate_seq=[RY], entangle_gate=X, depth=1).circuit     # 通过\n",
    "hams = [Hamiltonian(QubitOperator(f'Z{i}')) for i in [2, 3]]\n",
    "ansatz.summary()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms.set_context(mode=ms.PYNATIVE_MODE, device_target=\"CPU\")\n",
    "ms.set_seed(1)                                                     # 设置生成随机数的种子\n",
    "encoder = encoder.as_encoder()\n",
    "ansatz  = ansatz.as_ansatz()\n",
    "circuit = encoder.as_encoder() + ansatz.as_ansatz()         \n",
    "sim = Simulator('mqvector', 10)\n",
    "grad_ops = sim.get_expectation_with_grad(hams,\n",
    "                                         circuit,\n",
    "                                         parallel_worker=5)\n",
    "QuantumNet = MQLayer(grad_ops)          # 搭建量子神经网络\n",
    "QuantumNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore.nn import SoftmaxCrossEntropyWithLogits                         # 导入SoftmaxCrossEntropyWithLogits模块，用于定义损失函数\n",
    "from mindspore.nn import Adam                                                  # 导入Adam模块用于定义优化参数\n",
    "from mindspore.train import Accuracy, Model, LossMonitor                       # 导入Accuracy模块，用于评估预测准确率\n",
    "import mindspore as ms\n",
    "from mindspore.dataset import NumpySlicesDataset\n",
    "from torch.utils.data import DataLoader# 导入NumpySlicesDataset模块，用于创建模型可以识别的数据集\n",
    "\n",
    "loss = SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')            # 通过SoftmaxCrossEntropyWithLogits定义损失函数，sparse=True表示指定标签使用稀疏格式，reduction='mean'表示损失函数的降维方法为求平均值\n",
    "opti = Adam(QuantumNet.trainable_params(), learning_rate=0.1)                  # 通过Adam优化器优化Ansatz中的参数，需要优化的是Quantumnet中可训练的参数，学习率设为0.1\n",
    "\n",
    "model = Model(QuantumNet, loss, opti, metrics={'Acc': Accuracy()})             # 建立模型：将MindSpore Quantum构建的量子机器学习层和MindSpore的算子组合，构成一张更大的机器学习网络\n",
    "\n",
    "X_train_for_loader = X_train.numpy().reshape(-1,28*28)\n",
    "# 计算需要填充的列数\n",
    "padding_size = 1022 - X_train_for_loader.shape[1]\n",
    "X_train_for_loader = np.pad(X_train_for_loader, ((0, 0), (0, padding_size)), mode='constant')\n",
    "\n",
    "\n",
    "# 将值 3 替换为 1\n",
    "y_train[y_train == 3] = 1\n",
    "# 将值 6 替换为 0\n",
    "y_train[y_train == 6] = 1\n",
    "y_train_for_loader = y_train.numpy()\n",
    "\n",
    "X_test_for_loader = X_test.numpy().reshape(-1,28*28)\n",
    "padding_size = 1022 - X_test_for_loader.shape[1]\n",
    "X_test_for_loader = np.pad(X_test_for_loader, ((0, 0), (0, padding_size)), mode='constant')\n",
    "\n",
    "\n",
    "y_test[y_test == 3] = 1\n",
    "# 将值 6 替换为 0\n",
    "y_test[y_test == 6] = 1\n",
    "y_test_for_loader = y_test.numpy()\n",
    "\n",
    "train_loader = NumpySlicesDataset({'features': X_train_for_loader, 'labels': y_train_for_loader}, shuffle=False).batch(5) # 通过NumpySlicesDataset创建训练样本的数据集，shuffle=False表示不打乱数据，batch(5)表示训练集每批次样本点有5个\n",
    "test_loader = NumpySlicesDataset({'features': X_test_for_loader, 'labels': y_test_for_loader}).batch(5)                   # 通过NumpySlicesDataset创建测试样本的数据集，batch(5)表示测试集每批次样本点有5个\n",
    "\n",
    "\n",
    "class StepAcc(ms.Callback):                                                      # 定义一个关于每一步准确率的回调函数\n",
    "    def __init__(self, model, test_loader):\n",
    "        self.model = model\n",
    "        self.test_loader = test_loader\n",
    "        self.acc = []\n",
    "\n",
    "    def on_train_step_end(self, run_context):\n",
    "        self.acc.append(self.model.eval(self.test_loader, dataset_sink_mode=False)['Acc'])\n",
    "\n",
    "\n",
    "monitor = LossMonitor(20)                                                       # 监控训练中的损失，每16步打印一次损失值\n",
    "\n",
    "acc = StepAcc(model, test_loader)                                               # 使用建立的模型和测试样本计算预测的准确率\n",
    "\n",
    "model.train(20, train_loader, callbacks=[monitor, acc], dataset_sink_mode=False)# 将上述建立好的模型训练20次\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[y_test == 3] = 1\n",
    "y_test[y_test == 6] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[y_test == 3] = 1\n",
    "y_test[y_test == 6] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_for_loder = X_train.numpy().reshape(-1,28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_for_loder.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_for_loader = X_train.numpy().reshape(-1, 28*28)\n",
    "\n",
    "# 计算需要填充的列数\n",
    "padding_size = 1022 - X_train_for_loader.shape[1]\n",
    "\n",
    "# 使用 numpy.pad 进行填充\n",
    "X_train_padded = np.pad(X_train_for_loader, ((0, 0), (0, padding_size)), mode='constant')\n",
    "X_train_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
