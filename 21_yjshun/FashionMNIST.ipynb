{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Quantum Neural Network Classifiers: A Tutorial\n",
                "\n",
                "## 项目介绍\n",
                "\n",
                "该论文主要讨论了在量子神经网络的不同编码结构和编码策略在解决监督学习任务时的区别。文章对幅度编码和块编码在量子神经网络处理二分类问题时的表现进行了对比。作为测试基准，Fashion MNIST、MNIST、对称性保护拓扑态等数据集用来作为识别训练任务。本次论文复现要求：研究并理解文章内容,利用MindQuantum实现对Table 2中 对Fashion Mnist及MNIST的分类任务的结果。原文链接：https://scipost.org/SciPostPhysLectNotes.61\n",
                "\n",
                "## 复现过程\n",
                "\n",
                "### 数据预处理\n",
                "原文章主要讨论的是利用量子神经网络在二分类问题中的应用，具体任务设置为对Fashion MNIST中对靴子和T恤图片进行分类，对MNIST中的手写体“0”和“1”进行分类。初始数据为.mat格式，想要用于训练我们需要对其进行预处理"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/opt/miniconda3/envs/MindSpore/lib/python3.9/site-packages/mindquantum/simulator/__init__.py:17: UserWarning: Unable import mqvector gpu backend due to: cannot import name '_mq_vector_gpu' from partially initialized module 'mindquantum' (most likely due to a circular import) (/opt/miniconda3/envs/MindSpore/lib/python3.9/site-packages/mindquantum/__init__.py)\n",
                        "  from .available_simulator import SUPPORTED_SIMULATOR\n"
                    ]
                }
            ],
            "source": [
                "import numpy as np                                          \n",
                "from mindquantum.core.circuit import Circuit                \n",
                "from mindquantum.core.gates import H, RX, RY, RZ,X    \n",
                "from mindquantum.core.parameterresolver import PRGenerator  \n",
                "from mindquantum.simulator import Simulator\n",
                "from sklearn.datasets import fetch_openml\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.decomposition import PCA\n",
                "from sklearn.model_selection import train_test_split   \n",
                "from mindquantum.algorithm.library import amplitude_encoder\n",
                "from mindquantum.algorithm.nisq import HardwareEfficientAnsatz     \n",
                "from mindquantum.core.operators import QubitOperator           # 导入QubitOperator模块，用于构造泡利算符\n",
                "from mindquantum.core.operators import Hamiltonian             # 导入Hamiltonian模块，用于构建哈密顿量\n",
                "import mindspore as ms                                                                         # 导入mindspore库并简写为ms\n",
                "from mindquantum.framework import MQLayer,MQN2Layer                                              # 导入MQLayer\n",
                "# 导入HardwareEfficientAnsatz\n",
                "from mindquantum.core.gates import RY           \n",
                "import torch\n",
                "from torchvision import datasets, transforms# 导入量子门RY\n",
                "from scipy.ndimage import zoom\n",
                "import random"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(1204, 11, 11) torch.Size([1204])\n"
                    ]
                }
            ],
            "source": [
                "# 定义数据预处理\n",
                "transform = transforms.Compose([\n",
                "    transforms.ToTensor()\n",
                "])\n",
                "np.random.seed(10)\n",
                "def filter_3_and_6(data):\n",
                "    images, labels = data\n",
                "    mask = (labels == 3) | (labels == 6)\n",
                "    return images[mask], labels[mask]\n",
                "\n",
                "# 下载和加载 MNIST 数据集\n",
                "mnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
                "filtered_data = filter_3_and_6((mnist_dataset.data, mnist_dataset.targets))\n",
                "X_data, y = filtered_data  # X 图像数据 y 标签\n",
                "\n",
                "# 分别对标签为 3 和 6 的数据进行随机抽样\n",
                "def sample_data(X, y, label, sample_ratio=0.2):\n",
                "    label_mask = (y == label)\n",
                "    X_label = X[label_mask]\n",
                "    y_label = y[label_mask]\n",
                "    \n",
                "    sample_size = int(len(y_label) * sample_ratio)\n",
                "    sample_indices = np.random.choice(len(y_label), sample_size, replace=False)\n",
                "    \n",
                "    return X_label[sample_indices], y_label[sample_indices]\n",
                "\n",
                "X_data_3, y_data_3 = sample_data(X_data, y, label=3, sample_ratio=0.1)\n",
                "X_data_6, y_data_6 = sample_data(X_data, y, label=6, sample_ratio=0.1)\n",
                "\n",
                "# 合并抽样后的数据\n",
                "X_sampled = torch.cat((X_data_3, X_data_6), dim=0)\n",
                "y_sampled = torch.cat((y_data_3, y_data_6), dim=0)\n",
                "\n",
                "Compressed_X = np.array([zoom(img,0.4) for img in X_sampled])\n",
                "Compressed_X = Compressed_X/255\n",
                "\n",
                "print(Compressed_X.shape, y_sampled.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(963, 11, 11)\n",
                        "(241, 11, 11)\n"
                    ]
                }
            ],
            "source": [
                "X_train, X_test, y_train, y_test = train_test_split(Compressed_X, y_sampled, test_size=0.2, random_state=0, shuffle=True) # 将数据集划分为训练集和测试集\n",
                "y_train[y_train==3]=1\n",
                "y_train[y_train==6]=0\n",
                "y_test[y_test==3]=1\n",
                "y_test[y_test==6]=0\n",
                "print(X_train.shape)                                                                                   # 打印训练集中样本的数据类型\n",
                "print(X_test.shape)                                                                                    # 打印测试集中样本的数据类型"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "train_pixels和test_pixels分别为训练和测试用的像素数据，train_index和test_index为训练和测试标签。训练样本和测试样本大小分别为1000和200.\n",
                "\n",
                "可以通过matplotlib.pyplot对样本进行可视化"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "目前训练数据为像素数据，不能作为输入态直接用于量子线路，需要用幅度编码将像素数据转换为线路参量数据.\n",
                "\n",
                "mindquantum提供的mindquantum.algorithm.library.amplitude_encoder编码器可以方便地实现这一过程。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "from mindquantum.algorithm.library import amplitude_encoder\n",
                "def amplitude_param(pixels):\n",
                "    param_rd = []\n",
                "    _, parameterResolver = amplitude_encoder(pixels, 7)   \n",
                "    for _, param in parameterResolver.items():\n",
                "        param_rd.append(param)\n",
                "    param_rd = np.array(param_rd)\n",
                "    return param_rd\n",
                "\n",
                "# 将幅度转为编码线路参数，幅度shape(256,)，参数shape(255,)\n",
                "train_param = np.array([amplitude_param(i.flatten()) for i in X_train])\n",
                "test_param = np.array([amplitude_param(i.flatten()) for i in X_test])"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "将参数数据和标签封装ms.dataset.NumpySlicesDataset用于训练，数据预处理环节完成。\n",
                "\n",
                "该过程在main.py中Main()类的data_preporcess方法实现。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "import mindspore as ms\n",
                "BATCH_SIZE = 100\n",
                "train_loader = ms.dataset.NumpySlicesDataset(\n",
                "    {'features': train_param, 'labels': y_train}).batch(BATCH_SIZE) \n",
                "test_loader = ms.dataset.NumpySlicesDataset(\n",
                "    {'features': test_param, 'labels': y_test}).batch(BATCH_SIZE)  "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "ename": "TypeError",
                    "evalue": "'BatchDataset' object is not subscriptable",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_loader\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
                        "\u001b[0;31mTypeError\u001b[0m: 'BatchDataset' object is not subscriptable"
                    ]
                }
            ],
            "source": [
                "train_loader"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 量子线路搭建\n",
                "\n",
                "要实现数据分类需要定义含参ansatz线路。本次复现论文中提供三种ansatz，每个ansatz中包括参数层和纠缠层。\n",
                "\n",
                "一层参数层和一层纠缠层构成一个复合层(block)，复合层数越多说明ansatz线路越深。\n",
                "\n",
                "纠缠层有三种Ent1、Ent2、Ent3，所以三种ansatz对应的是三种纠缠层与参数层的组合。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "from mindquantum.core.circuit import Circuit\n",
                "import mindquantum.core.gates as Gate\n",
                "\n",
                "def Classifying_circuit(qubit_num, block_num, Ent_circ):\n",
                "    num = qubit_num\n",
                "    depth = block_num\n",
                "    circ = Circuit()\n",
                "    for i in range(depth):\n",
                "        circ = Para_circuit(circ, num)\n",
                "        if Ent_circ == 'Ent1':\n",
                "            circ = Ent1_circuit(circ, num)\n",
                "        elif Ent_circ == 'Ent2':\n",
                "            circ = Ent2_circuit(circ, num)\n",
                "        elif Ent_circ == 'Ent3':\n",
                "            circ = Ent3_circuit(circ, num)\n",
                "    return circ\n",
                "\n",
                "def Ent1_circuit(circuit,qubit_num):\n",
                "    for i in range(0,qubit_num-1,2):\n",
                "        circuit += Gate.Z.on(i+1,i)\n",
                "    for i in range(1,qubit_num-2,2):\n",
                "        circuit += Gate.Z.on(i+1,i)\n",
                "    return circuit\n",
                "\n",
                "def Ent2_circuit(circuit,qubit_num):\n",
                "    for i in range(0,qubit_num-1,2):\n",
                "        circuit += Gate.X.on(i+1,i)\n",
                "    for i in range(1,qubit_num-2,2):\n",
                "        circuit += Gate.X.on(i+1,i)\n",
                "    return circuit\n",
                "\n",
                "def Ent3_circuit(circuit,qubit_num):\n",
                "    circuit = Ent2_circuit(circuit,qubit_num)\n",
                "    circuit = Ent2_circuit(circuit,qubit_num)\n",
                "    return circuit\n",
                "\n",
                "def Para_circuit(circuit,qubit_num):\n",
                "    for i in range(qubit_num):\n",
                "        circuit += Gate.RX(f'Xtheta{i}').on(i)\n",
                "        circuit += Gate.RZ(f'Ztheta{i}').on(i)\n",
                "        circuit += Gate.RX(f'Xtheta2{i}').on(i)\n",
                "    return circuit"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Classifying_circuit(qubit_num, block_num, Ent_circ)可以通过传入比特数、复合层层数、纠缠层名称来定义ansatz"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "QUBIT_NUM = 10\n",
                "BLOCK_NUM = 2\n",
                "Ent = 'Ent3'\n",
                "ansatz = Classifying_circuit(QUBIT_NUM,BLOCK_NUM,Ent).as_ansatz()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "传入初态和比特数定义编码层"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "encoder = amplitude_encoder([0], QUBIT_NUM)[0].as_encoder()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "encoder.parameterized"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "随后通过Pauli-Z测量最后两个比特用于二分类，设置运行环境和全局种子后线路搭建完成。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "from mindquantum.framework import MQLayer\n",
                "from mindquantum.core.operators import Hamiltonian, QubitOperator\n",
                "from mindquantum.simulator import Simulator\n",
                "import mindspore as ms\n",
                "WORKER = 4\n",
                "ms.set_context(mode=ms.PYNATIVE_MODE, device_target=\"CPU\")\n",
                "ms.set_seed(1)\n",
                "circ = encoder.as_encoder() + ansatz\n",
                "meas = [Hamiltonian(QubitOperator(f'Z{i}')) for i in [QUBIT_NUM-2, QUBIT_NUM-1]]\n",
                "sim = Simulator('mqvector', circ.n_qubits)\n",
                "grad_ops = sim.get_expectation_with_grad(meas, circ, parallel_worker=WORKER)\n",
                "Qnet = MQLayer(grad_ops)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 模型训练"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ForwardAndLoss(ms.nn.Cell):\n",
                "    def __init__(self, backbone, loss_fn):\n",
                "        super(ForwardAndLoss, self).__init__(auto_prefix=False)\n",
                "        self.backbone = backbone\n",
                "        self.loss_fn = loss_fn\n",
                "\n",
                "    def construct(self, data, label):\n",
                "        output = self.backbone(data)\n",
                "        return self.loss_fn(output, label)\n",
                "\n",
                "    def backbone_network(self):\n",
                "        return self.backbone\n",
                "\n",
                "\n",
                "class TrainOneStep(ms.nn.TrainOneStepCell):\n",
                "\n",
                "    def __init__(self, network, optimizer):\n",
                "        super(TrainOneStep, self).__init__(network, optimizer)\n",
                "        self.grad = ms.ops.GradOperation(get_by_list=True)\n",
                "\n",
                "    def construct(self, data, label):\n",
                "        weights = self.weights\n",
                "        loss = self.network(data, label)\n",
                "        grads = self.grad(self.network, weights)(data, label)\n",
                "        return loss, self.optimizer(grads)\n",
                "\n",
                "LR = 0.05\n",
                "loss = ms.nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean') \n",
                "opt = ms.nn.Adam(Qnet.trainable_params(), learning_rate=LR) \n",
                "net_with_loss = ForwardAndLoss(Qnet, loss)\n",
                "train_one_step = TrainOneStep(net_with_loss, opt)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "定义评价标准"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [],
            "source": [
                "class EpochLoss(ms.nn.Metric):\n",
                "    def __init__(self):\n",
                "        super(EpochLoss, self).__init__()\n",
                "        self.clear()\n",
                "\n",
                "    def clear(self):\n",
                "        self.loss = 0\n",
                "        self.counter = 0\n",
                "\n",
                "    def update(self, *loss):\n",
                "        loss = loss[0].asnumpy()\n",
                "        self.loss += loss \n",
                "        self.counter += 1\n",
                "\n",
                "    def eval(self):\n",
                "        return self.loss / self.counter\n",
                "\n",
                "class EpochAcc(ms.nn.Metric):\n",
                "    def __init__(self):\n",
                "        super(EpochAcc, self).__init__()\n",
                "        self.clear()\n",
                "\n",
                "    def clear(self):\n",
                "        self.correct_num = 0\n",
                "        self.total_num = 0\n",
                "\n",
                "    def update(self, *inputs):\n",
                "        y_output = inputs[0].asnumpy()\n",
                "        y = inputs[1].asnumpy()\n",
                "        y_pred = np.zeros_like(y)\n",
                "        for i in range(y_pred.shape[0]):\n",
                "            yi = y_output[i]\n",
                "            if yi[0] >= yi[1]:\n",
                "                y_pred[i] = 0\n",
                "            else:\n",
                "                y_pred[i] = 1       \n",
                "        self.correct_num += np.sum(y == y_pred)\n",
                "        self.total_num += y.shape[0] \n",
                "\n",
                "    def eval(self):\n",
                "        return self.correct_num / self.total_num\n",
                "        \n",
                "acc_epoch = EpochAcc() \n",
                "loss_epoch = EpochLoss() "
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "开始训练"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "train_loss_epoch = []\n",
                "train_acc_epoch = []\n",
                "test_loss_epoch = []\n",
                "test_acc_epoch = []\n",
                "\n",
                "STEP_NUM = 30\n",
                "\n",
                "for epoch in range(STEP_NUM):\n",
                "    loss_epoch.clear() \n",
                "    acc_epoch.clear()\n",
                "    loss_epoch.clear()\n",
                "    acc_epoch.clear()\n",
                "\n",
                "    for data in train_loader: \n",
                "        train_one_step(data[0], data[1])   # 执行训练，并更新权重, data[0]参数，data[1]为标签\n",
                "        loss = net_with_loss(data[0], data[1])  \n",
                "        loss_epoch.update(loss) \n",
                "    train_loss = loss_epoch.eval() \n",
                "    train_loss_epoch.append(train_loss)\n",
                "\n",
                "    # training accuracy\n",
                "    for data in train_loader:\n",
                "        logits = Qnet(data[0]) # 向前传播得到预测值\n",
                "        acc_epoch.update(logits, data[1]) # 计算预测准确率\n",
                "    train_acc = acc_epoch.eval()\n",
                "    train_acc_epoch.append(train_acc)\n",
                "\n",
                "    # testing loss\n",
                "    for data in test_loader:\n",
                "        loss = net_with_loss(data[0], data[1])  # 计算损失值\n",
                "        loss_epoch.update(loss)\n",
                "    test_loss = loss_epoch.eval()\n",
                "    test_loss_epoch.append(test_loss)\n",
                "\n",
                "    # testing accuracy\n",
                "    for data in test_loader:\n",
                "        logits = Qnet(data[0])\n",
                "        acc_epoch.update(logits, data[1])\n",
                "    test_acc = acc_epoch.eval()\n",
                "    test_acc_epoch.append(test_acc)\n",
                "\n",
                "    print(f\"epoch: {epoch+1}, training loss: {train_loss}, training acc: {train_acc}, testing loss: {test_loss}, testing acc: {test_acc}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 项目总结\n",
                "\n",
                "原文中所给出的ansatz线路对FashionMNIST数据集中的二分类问题解析能力明显优于MNIST数据集。\n",
                "\n",
                "在FashionMNIST分类中，基于控制Z门的纠缠层Ent1表现优于基于控制X门的Ent2和Ent3；而在MNIST分类中，Ent2和Ent3表现优于Ent1，此结论与原文规律吻合。"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.19"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "d978e6baa1e26ab86251e765739ce2687cc7d01a83dd10a2a25d51a26c4053f6"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
