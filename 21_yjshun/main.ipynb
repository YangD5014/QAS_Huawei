{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Quantum Neural Network Classifiers: A Tutorial\n",
                "\n",
                "## 项目介绍\n",
                "\n",
                "该论文主要讨论了在量子神经网络的不同编码结构和编码策略在解决监督学习任务时的区别。文章对幅度编码和块编码在量子神经网络处理二分类问题时的表现进行了对比。作为测试基准，Fashion MNIST、MNIST、对称性保护拓扑态等数据集用来作为识别训练任务。本次论文复现要求：研究并理解文章内容,利用MindQuantum实现对Table 2中 对Fashion Mnist及MNIST的分类任务的结果。原文链接：https://scipost.org/SciPostPhysLectNotes.61\n",
                "\n",
                "## 复现过程\n",
                "\n",
                "### 数据预处理\n",
                "原文章主要讨论的是利用量子神经网络在二分类问题中的应用，具体任务设置为对Fashion MNIST中对靴子和T恤图片进行分类，对MNIST中的手写体“0”和“1”进行分类。初始数据为.mat格式，想要用于训练我们需要对其进行预处理"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import h5py \n",
                "import scipy.io\n",
                "import numpy as np\n",
                "\n",
                "train_num = 1000\n",
                "test_num = 200\n",
                "\n",
                "dataset = h5py.File('./Dataset/FashionMNIST_1_2_wk.mat')\n",
                "train_data = np.transpose(dataset['x_train'])\n",
                "train_label = np.transpose(dataset['y_train'])\n",
                "test_data = np.transpose(dataset['x_test'])\n",
                "test_label = np.transpose(dataset['y_test'])\n",
                "\n",
                "train_pixels = np.array(train_data[:,:train_num].tolist())[:,:,0].transpose() # [:,:,0]取实部\n",
                "test_pixels = np.array(test_data[:,:test_num].tolist())[:,:,0].transpose()\n",
                "train_index = train_label[:train_num,0].astype(int) # 0-> 靴子 1->T恤\n",
                "test_index = test_label[:test_num,0].astype(int)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_data[0].shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_data = np.transpose(dataset['x_test'])\n",
                "test_data.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "train_pixels和test_pixels分别为训练和测试用的像素数据，train_index和test_index为训练和测试标签。训练样本和测试样本大小分别为1000和200.\n",
                "\n",
                "可以通过matplotlib.pyplot对样本进行可视化"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "from matplotlib import gridspec\n",
                "plt.matshow(np.reshape(train_pixels[0,:],[16,16]))\n",
                "plt.matshow(np.reshape(train_pixels[1,:],[16,16]))\n",
                "print(f'前2个训练集标签为 {train_index[:2]}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_pixels[0].shape"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "目前训练数据为像素数据，不能作为输入态直接用于量子线路，需要用幅度编码将像素数据转换为线路参量数据.\n",
                "\n",
                "mindquantum提供的mindquantum.algorithm.library.amplitude_encoder编码器可以方便地实现这一过程。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from mindquantum.algorithm.library import amplitude_encoder\n",
                "def amplitude_param(pixels):\n",
                "    param_rd = []\n",
                "    _, parameterResolver = amplitude_encoder(pixels, 8)   \n",
                "    for _, param in parameterResolver.items():\n",
                "        param_rd.append(param)\n",
                "    param_rd = np.array(param_rd)\n",
                "    return param_rd\n",
                "\n",
                "# 将幅度转为编码线路参数，幅度shape(256,)，参数shape(255,)\n",
                "train_param = np.array([amplitude_param(i) for i in train_pixels ])\n",
                "test_param = np.array([amplitude_param(i) for i in test_pixels ])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_param = np.array([amplitude_param(i) for i in train_pixels ])\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "将参数数据和标签封装ms.dataset.NumpySlicesDataset用于训练，数据预处理环节完成。\n",
                "\n",
                "该过程在main.py中Main()类的data_preporcess方法实现。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "import mindspore as ms\n",
                "BATCH_SIZE = 100\n",
                "train_loader = ms.dataset.NumpySlicesDataset(\n",
                "    {'features': train_param, 'labels': train_index}, shuffle=True).batch(BATCH_SIZE) \n",
                "test_loader = ms.dataset.NumpySlicesDataset(\n",
                "    {'features': test_param, 'labels': test_index}).batch(BATCH_SIZE)  "
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 量子线路搭建\n",
                "\n",
                "要实现数据分类需要定义含参ansatz线路。本次复现论文中提供三种ansatz，每个ansatz中包括参数层和纠缠层。\n",
                "\n",
                "一层参数层和一层纠缠层构成一个复合层(block)，复合层数越多说明ansatz线路越深。\n",
                "\n",
                "纠缠层有三种Ent1、Ent2、Ent3，所以三种ansatz对应的是三种纠缠层与参数层的组合。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "from mindquantum.core.circuit import Circuit\n",
                "import mindquantum.core.gates as Gate\n",
                "\n",
                "def Classifying_circuit(qubit_num, block_num, Ent_circ):\n",
                "    num = qubit_num\n",
                "    depth = block_num\n",
                "    circ = Circuit()\n",
                "    for i in range(depth):\n",
                "        circ = Para_circuit(circ, num)\n",
                "        if Ent_circ == 'Ent1':\n",
                "            circ = Ent1_circuit(circ, num)\n",
                "        elif Ent_circ == 'Ent2':\n",
                "            circ = Ent2_circuit(circ, num)\n",
                "        elif Ent_circ == 'Ent3':\n",
                "            circ = Ent3_circuit(circ, num)\n",
                "    return circ\n",
                "\n",
                "def Ent1_circuit(circuit,qubit_num):\n",
                "    for i in range(0,qubit_num-1,2):\n",
                "        circuit += Gate.Z.on(i+1,i)\n",
                "    for i in range(1,qubit_num-2,2):\n",
                "        circuit += Gate.Z.on(i+1,i)\n",
                "    return circuit\n",
                "\n",
                "def Ent2_circuit(circuit,qubit_num):\n",
                "    for i in range(0,qubit_num-1,2):\n",
                "        circuit += Gate.X.on(i+1,i)\n",
                "    for i in range(1,qubit_num-2,2):\n",
                "        circuit += Gate.X.on(i+1,i)\n",
                "    return circuit\n",
                "\n",
                "def Ent3_circuit(circuit,qubit_num):\n",
                "    circuit = Ent2_circuit(circuit,qubit_num)\n",
                "    circuit = Ent2_circuit(circuit,qubit_num)\n",
                "    return circuit\n",
                "\n",
                "def Para_circuit(circuit,qubit_num):\n",
                "    for i in range(qubit_num):\n",
                "        circuit += Gate.RX(f'Xtheta{i}').on(i)\n",
                "        circuit += Gate.RZ(f'Ztheta{i}').on(i)\n",
                "        circuit += Gate.RX(f'Xtheta2{i}').on(i)\n",
                "    return circuit"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Classifying_circuit(qubit_num, block_num, Ent_circ)可以通过传入比特数、复合层层数、纠缠层名称来定义ansatz"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "QUBIT_NUM = 8\n",
                "BLOCK_NUM = 2\n",
                "Ent = 'Ent3'\n",
                "ansatz = Classifying_circuit(QUBIT_NUM,BLOCK_NUM,Ent).as_ansatz()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "传入初态和比特数定义编码层"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "encoder = amplitude_encoder([0], QUBIT_NUM)[0].as_encoder()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "encoder.parameterized"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "随后通过Pauli-Z测量最后两个比特用于二分类，设置运行环境和全局种子后线路搭建完成。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "from mindquantum.framework import MQLayer\n",
                "from mindquantum.core.operators import Hamiltonian, QubitOperator\n",
                "from mindquantum.simulator import Simulator\n",
                "import mindspore as ms\n",
                "from mindspore.nn import TrainOneStepCell\n",
                "WORKER = 4\n",
                "ms.set_context(mode=ms.PYNATIVE_MODE, device_target=\"CPU\")\n",
                "# ms.set_seed(1)\n",
                "circ = encoder.as_encoder() + ansatz\n",
                "meas = [Hamiltonian(QubitOperator(f'Z{i}')) for i in [QUBIT_NUM-2, QUBIT_NUM-1]]\n",
                "sim = Simulator('mqvector', circ.n_qubits)\n",
                "grad_ops = sim.get_expectation_with_grad(meas, circ, parallel_worker=WORKER)\n",
                "Qnet = MQLayer(grad_ops)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 模型训练"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ForwardAndLoss(ms.nn.Cell):\n",
                "    def __init__(self, backbone, loss_fn):\n",
                "        super(ForwardAndLoss, self).__init__(auto_prefix=False)\n",
                "        self.backbone = backbone\n",
                "        self.loss_fn = loss_fn\n",
                "\n",
                "    def construct(self, data, label):\n",
                "        output = self.backbone(data)\n",
                "        return self.loss_fn(output, label)\n",
                "\n",
                "    def backbone_network(self):\n",
                "        return self.backbone\n",
                "\n",
                "\n",
                "class TrainOneStep(ms.nn.TrainOneStepCell):\n",
                "\n",
                "    def __init__(self, network, optimizer):\n",
                "        super(TrainOneStep, self).__init__(network, optimizer)\n",
                "        self.grad = ms.ops.GradOperation(get_by_list=True)\n",
                "\n",
                "    def construct(self, data, label):\n",
                "        weights = self.weights\n",
                "        loss = self.network(data, label)\n",
                "        grads = self.grad(self.network, weights)(data, label)\n",
                "        return loss, self.optimizer(grads)\n",
                "\n",
                "LR = 0.05\n",
                "loss = ms.nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean') \n",
                "opt = ms.nn.Adam(Qnet.trainable_params(), learning_rate=LR) \n",
                "net_with_loss = ForwardAndLoss(Qnet, loss)\n",
                "train_one_step = TrainOneStep(net_with_loss, opt)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "定义评价标准"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "class EpochLoss(ms.nn.Metric):\n",
                "    def __init__(self):\n",
                "        super(EpochLoss, self).__init__()\n",
                "        self.clear()\n",
                "\n",
                "    def clear(self):\n",
                "        self.loss = 0\n",
                "        self.counter = 0\n",
                "\n",
                "    def update(self, *loss):\n",
                "        loss = loss[0].asnumpy()\n",
                "        self.loss += loss \n",
                "        self.counter += 1\n",
                "\n",
                "    def eval(self):\n",
                "        return self.loss / self.counter\n",
                "\n",
                "class EpochAcc(ms.nn.Metric):\n",
                "    def __init__(self):\n",
                "        super(EpochAcc, self).__init__()\n",
                "        self.clear()\n",
                "\n",
                "    def clear(self):\n",
                "        self.correct_num = 0\n",
                "        self.total_num = 0\n",
                "\n",
                "    def update(self, *inputs):\n",
                "        y_output = inputs[0].asnumpy()\n",
                "        y = inputs[1].asnumpy()\n",
                "        y_pred = np.zeros_like(y)\n",
                "        for i in range(y_pred.shape[0]):\n",
                "            yi = y_output[i]\n",
                "            if yi[0] >= yi[1]:\n",
                "                y_pred[i] = 0\n",
                "            else:\n",
                "                y_pred[i] = 1       \n",
                "        self.correct_num += np.sum(y == y_pred)\n",
                "        self.total_num += y.shape[0] \n",
                "\n",
                "    def eval(self):\n",
                "        return self.correct_num / self.total_num\n",
                "        \n",
                "acc_epoch = EpochAcc() \n",
                "loss_epoch = EpochLoss() "
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "开始训练"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "train_loss_epoch = []\n",
                "train_acc_epoch = []\n",
                "test_loss_epoch = []\n",
                "test_acc_epoch = []\n",
                "\n",
                "STEP_NUM = 30\n",
                "\n",
                "for epoch in range(STEP_NUM):\n",
                "    loss_epoch.clear() \n",
                "    acc_epoch.clear()\n",
                "    loss_epoch.clear()\n",
                "    acc_epoch.clear()\n",
                "\n",
                "    for data in train_loader: \n",
                "        train_one_step(data[0], data[1])   # 执行训练，并更新权重, data[0]参数，data[1]为标签\n",
                "        loss = net_with_loss(data[0], data[1])  \n",
                "        loss_epoch.update(loss) \n",
                "    train_loss = loss_epoch.eval() \n",
                "    train_loss_epoch.append(train_loss)\n",
                "\n",
                "    # training accuracy\n",
                "    for data in train_loader:\n",
                "        logits = Qnet(data[0]) # 向前传播得到预测值\n",
                "        acc_epoch.update(logits, data[1]) # 计算预测准确率\n",
                "    train_acc = acc_epoch.eval()\n",
                "    train_acc_epoch.append(train_acc)\n",
                "\n",
                "    # testing loss\n",
                "    for data in test_loader:\n",
                "        loss = net_with_loss(data[0], data[1])  # 计算损失值\n",
                "        loss_epoch.update(loss)\n",
                "    test_loss = loss_epoch.eval()\n",
                "    test_loss_epoch.append(test_loss)\n",
                "\n",
                "    # testing accuracy\n",
                "    for data in test_loader:\n",
                "        logits = Qnet(data[0])\n",
                "        acc_epoch.update(logits, data[1])\n",
                "    test_acc = acc_epoch.eval()\n",
                "    test_acc_epoch.append(test_acc)\n",
                "\n",
                "    print(f\"epoch: {epoch+1}, training loss: {train_loss}, training acc: {train_acc}, testing loss: {test_loss}, testing acc: {test_acc}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 项目总结\n",
                "\n",
                "原文中所给出的ansatz线路对FashionMNIST数据集中的二分类问题解析能力明显优于MNIST数据集。\n",
                "\n",
                "在FashionMNIST分类中，基于控制Z门的纠缠层Ent1表现优于基于控制X门的Ent2和Ent3；而在MNIST分类中，Ent2和Ent3表现优于Ent1，此结论与原文规律吻合。"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "MindSpore",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.19"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
