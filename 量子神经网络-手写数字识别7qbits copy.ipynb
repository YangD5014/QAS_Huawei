{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                          \n",
    "from mindquantum.core.circuit import Circuit                \n",
    "from mindquantum.core.gates import H, RX, RY, RZ,X    \n",
    "from mindquantum.core.parameterresolver import PRGenerator  \n",
    "from mindquantum.simulator import Simulator\n",
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split   \n",
    "from mindquantum.algorithm.library import amplitude_encoder\n",
    "from mindquantum.algorithm.nisq import HardwareEfficientAnsatz     \n",
    "from mindquantum.core.operators import QubitOperator           # 导入QubitOperator模块，用于构造泡利算符\n",
    "from mindquantum.core.operators import Hamiltonian             # 导入Hamiltonian模块，用于构建哈密顿量\n",
    "import mindspore as ms                                                                         # 导入mindspore库并简写为ms\n",
    "from mindquantum.framework import MQLayer,MQN2Layer                                              # 导入MQLayer\n",
    "# 导入HardwareEfficientAnsatz\n",
    "from mindquantum.core.gates import RY           \n",
    "import torch\n",
    "from torchvision import datasets, transforms# 导入量子门RY\n",
    "from scipy.ndimage import zoom\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "np.random.seed(10)\n",
    "def filter_3_and_6(data):\n",
    "    images, labels = data\n",
    "    mask = (labels == 3) | (labels == 6)\n",
    "    return images[mask], labels[mask]\n",
    "\n",
    "# 下载和加载 MNIST 数据集\n",
    "mnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "filtered_data = filter_3_and_6((mnist_dataset.data, mnist_dataset.targets))\n",
    "X_data, y = filtered_data  # X 图像数据 y 标签\n",
    "\n",
    "# 分别对标签为 3 和 6 的数据进行随机抽样\n",
    "def sample_data(X, y, label, sample_ratio=0.2):\n",
    "    label_mask = (y == label)\n",
    "    X_label = X[label_mask]\n",
    "    y_label = y[label_mask]\n",
    "    \n",
    "    sample_size = int(len(y_label) * sample_ratio)\n",
    "    sample_indices = np.random.choice(len(y_label), sample_size, replace=False)\n",
    "    \n",
    "    return X_label[sample_indices], y_label[sample_indices]\n",
    "\n",
    "X_data_3, y_data_3 = sample_data(X_data, y, label=3, sample_ratio=0.2)\n",
    "X_data_6, y_data_6 = sample_data(X_data, y, label=6, sample_ratio=0.2)\n",
    "\n",
    "# 合并抽样后的数据\n",
    "X_sampled = torch.cat((X_data_3, X_data_6), dim=0)\n",
    "y_sampled = torch.cat((y_data_3, y_data_6), dim=0)\n",
    "\n",
    "Compressed_X = np.array([zoom(img,0.4) for img in X_sampled])\n",
    "Compressed_X = Compressed_X/255\n",
    "\n",
    "# Compressed_X = Compressed_X[:1200]\n",
    "# y_sampled = y_sampled[:1200]\n",
    "\n",
    "# y_sampled[y_sampled ==3] =1\n",
    "# y_sampled[y_sampled ==6] =0\n",
    "\n",
    "# Compressed_X = torch.tensor(Compressed_X, dtype=torch.float32)\n",
    "\n",
    "print(Compressed_X.shape, y_sampled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Compressed_X, y_sampled, test_size=0.2, random_state=0, shuffle=True) # 将数据集划分为训练集和测试集\n",
    "y_train[y_train==3]=1\n",
    "y_train[y_train==6]=0\n",
    "y_test[y_test==3]=1\n",
    "y_test[y_test==6]=0\n",
    "print(X_train.shape)                                                                                   # 打印训练集中样本的数据类型\n",
    "print(X_test.shape)                                                                                    # 打印测试集中样本的数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amplitude_param(pixels):\n",
    "    param_rd = []\n",
    "    _, parameterResolver = amplitude_encoder(pixels, 6)   \n",
    "    for _, param in parameterResolver.items():\n",
    "        param_rd.append(param)\n",
    "    param_rd = np.array(param_rd)\n",
    "    return param_rd\n",
    "\n",
    "trian_params = np.array([amplitude_param(pixels=i.flatten()) for i in X_train])\n",
    "test_params  = np.array([amplitude_param(pixels=i.flatten()) for i in X_test])\n",
    "print(f'trian_params shape={trian_params.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prg = PRGenerator('alpha')\n",
    "# encoder = Circuit()\n",
    "encoder, parameterResolver  = amplitude_encoder([0],6)\n",
    "encoder = encoder.as_encoder()\n",
    "encoder = encoder.no_grad()\n",
    "ansatz = HardwareEfficientAnsatz(6, single_rot_gate_seq=[RY], entangle_gate=X, depth=3).circuit     # 通过\n",
    "hams = [Hamiltonian(QubitOperator(f'Z{i}')) for i in [0,1]]\n",
    "\n",
    "ms.set_context(mode=ms.PYNATIVE_MODE, device_target=\"CPU\")\n",
    "ms.set_seed(2)                                                     # 设置生成随机数的种子\n",
    "circuit = encoder+ ansatz.as_ansatz()         \n",
    "sim = Simulator('mqvector', 6)\n",
    "grad_ops = sim.get_expectation_with_grad(hams,\n",
    "                                         circuit,\n",
    "                                         parallel_worker=5)\n",
    "QuantumNet = MQLayer(grad_ops)          # 搭建量子神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore.nn import SoftmaxCrossEntropyWithLogits                         # 导入SoftmaxCrossEntropyWithLogits模块，用于定义损失函数\n",
    "from mindspore.nn import Adam                                                  # 导入Adam模块用于定义优化参数\n",
    "from mindspore.train import Accuracy, Model, LossMonitor                       # 导入Accuracy模块，用于评估预测准确率\n",
    "import mindspore as ms\n",
    "from mindspore.dataset import NumpySlicesDataset\n",
    "from torch.utils.data import DataLoader# 导入NumpySlicesDataset模块，用于创建模型可以识别的数据集\n",
    "\n",
    "\n",
    "\n",
    "loss = SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')            # 通过SoftmaxCrossEntropyWithLogits定义损失函数，sparse=True表示指定标签使用稀疏格式，reduction='mean'表示损失函数的降维方法为求平均值\n",
    "opti = Adam(QuantumNet.trainable_params(), learning_rate=0.1)                  # 通过Adam优化器优化Ansatz中的参数，需要优化的是Quantumnet中可训练的参数，学习率设为0.1\n",
    "\n",
    "model = Model(QuantumNet, loss, opti, metrics={'Acc': Accuracy()})             # 建立模型：将MindSpore Quantum构建的量子机器学习层和MindSpore的算子组合，构成一张更大的机器学习网络\n",
    "\n",
    "y_test[y_test == 3] = 1\n",
    "# 将值 6 替换为 0\n",
    "y_test[y_test == 6] = 0\n",
    "y_test_for_loader = y_test.numpy()\n",
    "\n",
    "train_loader = NumpySlicesDataset({'features': trian_params, 'labels': y_train}, shuffle=False).batch(20) # 通过NumpySlicesDataset创建训练样本的数据集，shuffle=False表示不打乱数据，batch(5)表示训练集每批次样本点有5个\n",
    "test_loader = NumpySlicesDataset({'features': test_params, 'labels': y_test},shuffle=False).batch(20)                   # 通过NumpySlicesDataset创建测试样本的数据集，batch(5)表示测试集每批次样本点有5个\n",
    "\n",
    "\n",
    "class StepAcc(ms.Callback):                                                      # 定义一个关于每一步准确率的回调函数\n",
    "    def __init__(self, model, test_loader):\n",
    "        self.model = model\n",
    "        self.test_loader = test_loader\n",
    "        self.acc = []\n",
    "\n",
    "    def on_train_step_end(self, run_context):\n",
    "        \n",
    "        self.acc.append(self.model.eval(self.test_loader, dataset_sink_mode=False)['Acc'])\n",
    "        # print(f'ACC = {self.acc[-1]}')\n",
    "\n",
    "\n",
    "monitor = LossMonitor(100)                                                       # 监控训练中的损失，每16步打印一次损失值\n",
    "\n",
    "acc = StepAcc(model, test_loader)                                               # 使用建立的模型和测试样本计算预测的准确率\n",
    "\n",
    "model.train(30, train_loader, callbacks=[monitor, acc], dataset_sink_mode=False)# 将上述建立好的模型训练20次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(acc.acc)\n",
    "plt.title('Statistics of accuracy', fontsize=20)\n",
    "plt.xlabel('Steps', fontsize=20)\n",
    "plt.ylabel('Accuracy', fontsize=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
